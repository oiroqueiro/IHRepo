{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "#Connect to mysql\n",
    "import mysql.connector\n",
    "\n",
    "#Operating system\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "#import subprocess\n",
    "#from threading import Thread\n",
    "\n",
    "#Pandas\n",
    "import pandas as pd\n",
    "\n",
    "#Regex\n",
    "import re\n",
    "\n",
    "#Transcription & subtitles\n",
    "import whisper\n",
    "import stable_whisper\n",
    "\n",
    "#Keywords\n",
    "from keybert import KeyBERT\n",
    "import tensorflow_hub\n",
    "\n",
    "#Summary\n",
    "from transformers import pipeline\n",
    "\n",
    "#Translation\n",
    "import translators as ts\n",
    "import translators.server as tss\n",
    "import textwrap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connection_ddbb():\n",
    "    \"\"\"Function to create the conection to the data base\n",
    "    \n",
    "    Keyword arguments:    \n",
    "    Return: connection objet, secrets object\n",
    "    \"\"\"\n",
    "       \n",
    "    secrets={}\n",
    "    #secrets_file = open('secrets.txt','r') #Had errors using this within a virtual environment\n",
    "    secrets_file = os.fdopen(os.open('secrets.txt', os.O_RDONLY))\n",
    "    for line in secrets_file:\n",
    "        (key, val) = line.replace('\\n','').split(\"|\")\n",
    "        secrets[key] = val    \n",
    "\n",
    "    #Conection to mysql\n",
    "\n",
    "    conn = mysql.connector.connect(user=secrets['user'],\n",
    "                            password=secrets['pass'],\n",
    "                            host=secrets['server'])\n",
    "    \n",
    "    return conn, secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection, secrets = connection_ddbb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ddbb(_conn,_secrets):\n",
    "    \"\"\"Function to create the data base\n",
    "    \n",
    "    Keyword arguments:  \n",
    "    _conn: connection object \n",
    "    _secrets: secrets object \n",
    "    Return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    #connection_ddbb\n",
    "    \n",
    "    #Creating schema in mysql\n",
    "\n",
    "    if _conn.is_connected():\n",
    "        cursor = _conn.cursor()\n",
    "\n",
    "        print('Connection open')        \n",
    "        \n",
    "        print('Creating database if necessary...')\n",
    "        \n",
    "        query = ('CREATE DATABASE IF NOT EXISTS ironrep')\n",
    "        \n",
    "        cursor.execute(query)\n",
    "        _conn.commit()\n",
    "        \n",
    "        query = ('USE ironrep')\n",
    "        \n",
    "        cursor.execute(query)\n",
    "        _conn.commit()\n",
    "        \n",
    "        print('Database created if necessary...')\n",
    "\n",
    "        print('Creating tables if necessary...')\n",
    "\n",
    "        #Configuration        \n",
    "        \n",
    "        print('     - Configuration...')\n",
    "\n",
    "        query = (\"\"\"CREATE TABLE IF NOT EXISTS ironrep.configuration (  \n",
    "                        id enum('1') PRIMARY KEY NOT NULL,\n",
    "                        temp_directory  nvarchar(250),\n",
    "                        video_player nvarchar(250),\n",
    "                        languages_subtitles nvarchar(250) COMMENT 'List of langages codes separated by commas')\"\"\")\n",
    "\n",
    "        cursor.execute(query)    \n",
    "        _conn.commit()\n",
    "\n",
    "        #Default values\n",
    "        query = (\"\"\"REPLACE INTO ironrep.configuration (temp_directory,video_player,languages_subtitles)\n",
    "                        VALUES (%s,%s,%s)\"\"\")\n",
    "        val = (str(_secrets['temp_dir']),str(_secrets['video_play']),str(_secrets['lang_subt']))\n",
    "        \"\"\"val = (str('/home/roque/01. IronHack/00. Data Analytics/01. Course/63. Week 23 - Day 3/git/final-project-bootcamp/data/'),\n",
    "                str(\"vlc '{videoparam}' --sub-file '{subtitleparam}' --no-sub-autodetect-file --start-time '{positionparam}'\"),\n",
    "                str('es,pt,it,zh,de,hi'))\"\"\"\n",
    "        cursor.execute(query,val)\n",
    "        _conn.commit()\n",
    "\n",
    "        #Videos\n",
    "\n",
    "        print('     - Videos...')\n",
    "\n",
    "        query = (\"\"\"CREATE TABLE IF NOT EXISTS ironrep.videos (\n",
    "                        id INT PRIMARY KEY NOT NULL AUTO_INCREMENT,\n",
    "                        video_name nvarchar(250),\n",
    "                        video_path nvarchar(250)\n",
    "                    )\"\"\"\n",
    "        )\n",
    "\n",
    "        cursor.execute(query)    \n",
    "        _conn.commit()\n",
    "\n",
    "        print('     - Videos (index)...')\n",
    "\n",
    "        query = (\"\"\"ALTER TABLE ironrep.videos ADD FULLTEXT(video_name)\"\"\"\n",
    "        )\n",
    "\n",
    "        cursor.execute(query)    \n",
    "        _conn.commit()\n",
    "\n",
    "        #Transcriptions\n",
    "\n",
    "        print('     - Transcriptions...')\n",
    "\n",
    "        query = (\"\"\"CREATE TABLE IF NOT EXISTS ironrep.transcriptions (\n",
    "                        id INT PRIMARY KEY NOT NULL AUTO_INCREMENT,\n",
    "                        videoid INT NOT NULL,\n",
    "                        languageid nvarchar(5),\n",
    "                        transcription mediumtext\n",
    "                    )\"\"\"\n",
    "        )\n",
    "\n",
    "        cursor.execute(query)    \n",
    "        _conn.commit()\n",
    "\n",
    "        #Transcriptions index\n",
    "\n",
    "        print('     - Transcriptions (index)...')\n",
    "\n",
    "        query = (\"\"\"ALTER TABLE ironrep.transcriptions ADD FULLTEXT(transcription)\"\"\"\n",
    "        )\n",
    "\n",
    "        cursor.execute(query)    \n",
    "        _conn.commit()\n",
    "\n",
    "\n",
    "        #Summaries\n",
    "\n",
    "        print('     - Summaries...')\n",
    "\n",
    "        query = (\"\"\"CREATE TABLE IF NOT EXISTS ironrep.summaries (\n",
    "                        videoid INT NOT NULL,\n",
    "                        languageid nvarchar(5),\n",
    "                        summary TEXT                   \n",
    "                    )\"\"\"\n",
    "        )\n",
    "\n",
    "        cursor.execute(query)    \n",
    "        _conn.commit()\n",
    "\n",
    "        print('     - Summaries (index)...')\n",
    "\n",
    "        query = (\"\"\"ALTER TABLE ironrep.summaries ADD FULLTEXT(summary)\"\"\"\n",
    "        )\n",
    "\n",
    "        cursor.execute(query)    \n",
    "        _conn.commit()\n",
    "\n",
    "        #Subtitles\n",
    "\n",
    "        print('     - Subtitles...')\n",
    "        \n",
    "        query = (\"\"\"CREATE TABLE IF NOT EXISTS ironrep.subtitles (\n",
    "                        id INT PRIMARY KEY NOT NULL AUTO_INCREMENT,\n",
    "                        videoid INT NOT NULL,\n",
    "                        languageid nvarchar(5),\n",
    "                        subtitles mediumtext                   \n",
    "                    )\"\"\"\n",
    "        )\n",
    "\n",
    "        cursor.execute(query)    \n",
    "        _conn.commit()\n",
    "\n",
    "        print('     - Subtitles (index)...')\n",
    "\n",
    "        query = (\"\"\"ALTER TABLE ironrep.subtitles ADD FULLTEXT(subtitles)\"\"\"\n",
    "        )\n",
    "\n",
    "        cursor.execute(query)    \n",
    "        _conn.commit()\n",
    "\n",
    "        #Keywords\n",
    "\n",
    "        print('     - Keywords...')\n",
    "\n",
    "        query = (\"\"\"CREATE TABLE IF NOT EXISTS ironrep.keywords (\n",
    "                        id INT PRIMARY KEY NOT NULL AUTO_INCREMENT,\n",
    "                        videoid INT NOT NULL,\n",
    "                        languageid nvarchar(5),\n",
    "                        keywords nvarchar(250)                   \n",
    "                    )\"\"\"\n",
    "        )\n",
    "\n",
    "        cursor.execute(query)    \n",
    "        _conn.commit()\n",
    "\n",
    "        print('     - Keywords (index)...')\n",
    "\n",
    "        query = (\"\"\"ALTER TABLE ironrep.subtitles ADD FULLTEXT(keywords)\"\"\"\n",
    "        )\n",
    "\n",
    "        cursor.execute(query)    \n",
    "        _conn.commit()\n",
    "\n",
    "\n",
    "        print('Tables created if necessary...')\n",
    "    else:\n",
    "        print('Error connecting')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection open\n",
      "Creating database if necessary...\n",
      "Database created if necessary...\n",
      "Creating tables if necessary...\n"
     ]
    }
   ],
   "source": [
    "create_ddbb(connection, secrets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data_sql(_conn, _table, _videoid, _langid, _text):\n",
    "    \"\"\"Function to insert data in the database\n",
    "    \n",
    "    Keyword arguments:\n",
    "    _table: the object where insert ['video','transcription','subtitle','summary','keywords']\n",
    "    _videoid: the id of the video\n",
    "    _langid: the id of the language\n",
    "    _text: value to insert\n",
    "    Return: cursor\n",
    "    \"\"\"\n",
    "    \n",
    "    if _conn.is_connected():\n",
    "        cursor = _conn.cursor()\n",
    "        query = ''\n",
    "        val = []\n",
    "\n",
    "        if (_table == 'video'):                 \n",
    "            vid_path = os.path.split(os.path.abspath(Path(_text)))\n",
    "\n",
    "            query = \"\"\"INSERT INTO ironrep.videos(video,video_path)\n",
    "                        VALUES (%s,%s)\"\"\"\n",
    "            val = [vid_path[1].split('.')[0],_text]\n",
    "        elif (_table == 'transcription'):\n",
    "            query = \"\"\"INSERT INTO ironrep.transcriptions(videoid,languageid,transcription)\n",
    "                        VALUES (%s,%s,%s)\"\"\"\n",
    "            val = [int(_videoid),_langid,_text]\n",
    "        elif (_table == 'subtitle'):\n",
    "            query = \"\"\"INSERT INTO ironrep.subtitles(videoid,languageid,subtitles)\n",
    "                        VALUES (%s,%s,%s)\"\"\"\n",
    "            val = [int(_videoid),_langid,_text]\n",
    "        elif (_table == 'summary'):\n",
    "            query = \"\"\"INSERT INTO ironrep.summary(videoid,languageid,summary)\n",
    "                        VALUES (%s,%s,%s)\"\"\"\n",
    "            val = [int(_videoid),_langid,_text]\n",
    "        elif (_table == 'keywords'):\n",
    "            query = \"\"\"INSERT INTO ironrep.keywords(videoid,languageid,keywords)\n",
    "                        VALUES (%s,%s,%s)\"\"\"\n",
    "            val = [int(_videoid),_langid,_text]\n",
    "        else:\n",
    "            return 'none'\n",
    "\n",
    "        if (query != ''):      \n",
    "            cursor.execute(query,val)\n",
    "            _conn.commit()  \n",
    "            return cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(_conn, filepath):\n",
    "    \"\"\"\n",
    "    With this function we can transcribe all the texts from a video/audio and also the subtitles\n",
    "    \n",
    "    Keyword arguments:\n",
    "    argument -- filepath:the file to transcribe\n",
    "    Return: No return (insert in mysql and create 2 text files -temporary-)\n",
    "    \"\"\"\n",
    "    \n",
    "    video = os.path.split(os.path.abspath(Path(filepath)))\n",
    "    name = video[1].split(sep='.')\n",
    "\n",
    "    result_sql = insert_data_sql(_conn,'video', '', '', filepath)\n",
    "    videoid = result_sql.lastrowid\n",
    "    \n",
    "    # speech transcription\n",
    "    \n",
    "    model = whisper.load_model(\"base.en\",device='cpu')\n",
    "    #model = stable_whisper.load_model('base')\n",
    "\n",
    "    result = model.transcribe(filepath)\n",
    "    \n",
    "    with open(Path(video[0]+\"/\"+name[0]+\"_transcription.txt\"), \"w+\") as f:\n",
    "        f.write(result[\"text\"])\n",
    "\n",
    "    result_sql = insert_data_sql(_conn,'transcription', videoid, 'en', result['text'])\n",
    "\n",
    "    # subtitles \n",
    "    stable_whisper.results_to_sentence_srt(result, video[0]+\"/\"+name[0]+\"_subtitles.srt\")\n",
    "\n",
    "    text_subtitles = open(video[0]+\"/\"+name[0]+\"_subtitles.srt\").read()\n",
    "\n",
    "    result_sql = insert_data_sql(_conn,'subtitle', videoid, 'en', text_subtitles)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(_conn, _videoid):\n",
    "    \"\"\"Function to extract the top 50 keywords of the transcription\n",
    "    \n",
    "    Keyword arguments:\n",
    "    _conn: Connection to the database\n",
    "    _videoid: id of the video to extract the keywords\n",
    "    Return: Nothing\n",
    "    \"\"\"\n",
    "    \n",
    "    if _conn.is_connected():\n",
    "\n",
    "        cursor = connection.cursor(buffered=True)\n",
    "        query = \"\"\"SELECT videoid, languageid, transcription\n",
    "                    FROM ironrep.transcriptions\n",
    "                    WHERE videoid = %s and languageid = %s\"\"\"\n",
    "        val = [int(_videoid),str('en')]\n",
    "        cursor.execute(query,val)\n",
    "        \n",
    "        trans_table = cursor.fetchall()\n",
    "        if (len(trans_table)>0):            \n",
    "            #trans_df = pd.DataFrame(trans_table)\n",
    "            #trans_df.columns = [i[0] for i in cursor.description]                                            \n",
    "            for transcription in trans_table:                \n",
    "                max_ngram_size = 2\n",
    "                deduplication_threshold = 0.1\n",
    "                numOfKeywords = 50\n",
    "\n",
    "                extracted_keyword = []\n",
    "\n",
    "                embedding_model = tensorflow_hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")                \n",
    "                kw_model = KeyBERT(model=embedding_model)\n",
    "                extracted_keyword = kw_model.extract_keywords(transcription[2], keyphrase_ngram_range=(1, max_ngram_size), top_n=numOfKeywords, diversity=deduplication_threshold)\n",
    "                #print(extracted_keyword)\n",
    "                for keyw,_ in sorted(extracted_keyword, key=lambda x: x[1],reverse=True):\n",
    "                    result_sql = insert_data_sql(_conn,'keywords',_videoid,'en',keyw)\n",
    "        else:\n",
    "            print('No video transcription to extract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_keywords(connection,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary(_conn, _videoid):\n",
    "    \"\"\"Function to create one summary of the text transcripted in english\n",
    "    \n",
    "    Keyword arguments:\n",
    "    _conn: the connection to the database\n",
    "    _videoid: the id of the video to summarize\n",
    "    Return: Nothing\n",
    "    \"\"\"\n",
    "    if _conn.is_connected():\n",
    "\n",
    "        cursor = connection.cursor(buffered=True)\n",
    "        query = \"\"\"SELECT videoid, languageid, transcription\n",
    "                    FROM ironrep.transcriptions\n",
    "                    WHERE videoid = %s and languageid = %s\"\"\"\n",
    "        val = [int(_videoid),str('en')]\n",
    "        cursor.execute(query,val)\n",
    "        \n",
    "        trans_table = cursor.fetchall()\n",
    "        if (len(trans_table)>0):                                                     \n",
    "            for transcription in trans_table:                \n",
    "                hub_model_id = \"mrm8488/flan-t5-large-finetuned-openai-summarize_from_feedback\"\n",
    "\n",
    "                summary = ''\n",
    "\n",
    "                hub_model_id = \"mrm8488/flan-t5-large-finetuned-openai-summarize_from_feedback\" #OK Muy bueno 1m\n",
    "                summarizer = pipeline(\"summarization\", model=hub_model_id)\n",
    "                summary = summarizer(' '.join(transcription.split(' ')[:250]), max_length=250)\n",
    "\n",
    "                result_sql = insert_data_sql(_conn,'summary',_videoid,'en',summary[0]['summary_text'])\n",
    "        else:\n",
    "            print('No video summary to create')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_from_en(text_en,to_language):\n",
    "    \"\"\"FUNCTION TO TRANSLATE THE TEXT FROM ENGLISH TO ANY LANGUAGE\n",
    "    \n",
    "    Keyword arguments:\n",
    "    text_en: text in english\n",
    "    to_language: the code of the language to translate (es,zh, ...) \n",
    "    Return: text translated\n",
    "    \"\"\"\n",
    "    \n",
    "    if (to_language==''):\n",
    "        display('Need to include the language to translate.')\n",
    "    else:\n",
    "        ts.translators_pool\n",
    "\n",
    "        text_translated = ''\n",
    "        \n",
    "        from_language = 'en'\n",
    "            \n",
    "        \n",
    "        if (len(text_en)>2000):\n",
    "            textsplited_to = []\n",
    "            text_splited = textwrap.wrap(text_en, 2000, break_long_words=False)\n",
    "            for line in text_splited:\n",
    "                textsplited_to.append(tss.google(line, from_language, to_language))\n",
    "            text_translated = ' '.join(textsplited_to)\n",
    "        else:\n",
    "            try:\n",
    "                text_translated = tss.google(text_en, from_language, to_language)\n",
    "            except:\n",
    "                try:\n",
    "                    text_translated = ts.translate_text(text_en, from_language, to_language)\n",
    "                except:\n",
    "                    text_translated = text_en\n",
    "\n",
    "    return text_translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_subtitles(_conn, _videoid):\n",
    "    if _conn.is_connected():\n",
    "\n",
    "        cursor_conf = connection.cursor(buffered=True)\n",
    "\n",
    "        query_conf = \"\"\"SELECT languages_subtitles, temp_directory \n",
    "                        FROM ironrep.configuration\n",
    "                        LIMIT 1;\"\"\"\n",
    "        cursor_conf.execute(query_conf)\n",
    "\n",
    "        conf_table = cursor_conf.fetchall()\n",
    "        conf_df = pd.DataFrame(conf_table)\n",
    "        conf_df.columns = [i[0] for i in cursor_conf.description]\n",
    "\n",
    "        cursor = connection.cursor(buffered=True)\n",
    "        query = \"\"\"SELECT videoid, languageid, subtitles\n",
    "                    FROM ironrep.subtitles\n",
    "                    WHERE videoid = %s and languageid = %s\"\"\"\n",
    "        val = [int(_videoid),str('en')]\n",
    "        cursor.execute(query,val)\n",
    "        \n",
    "        subt_table = cursor.fetchall()\n",
    "        subt_df = pd.DataFrame(subt_table)\n",
    "        subt_df.columns = [i[0] for i in cursor.description]\n",
    "        \n",
    "        translated = []\n",
    "        text_subtitles = ''\n",
    "\n",
    "        #We discard 'en' language since this approach will work from English, not multilingual option.\n",
    "        for lang in [language for languages in conf_df['languages_subtitles'].str.split(',') for language in languages if language != 'en']:\n",
    "            for sub in subt_table:\n",
    "                #print(lang)\n",
    "                for row in sub[2].split('\\n'):\n",
    "                    translated.append(translate_from_en(row,lang))                    \n",
    "                \n",
    "            with open(Path(list(conf_df['temp_directory'])[0]+\"/\"+lang+\"_subtitle_tmp.srt\"), mode='wt', encoding='utf-8') as f:    \n",
    "                f.write('\\n'.join(translated))\n",
    "\n",
    "            text_subtitles = open(Path(list(conf_df['temp_directory'])[0]+\"/\"+lang+\"_subtitle_tmp.srt\")).read().replace(' -> ',' --> ').replace(': ',':')\n",
    "\n",
    "            result_sql = insert_data_sql(connection,'subtitle', _videoid, lang, text_subtitles)\n",
    "\n",
    "            os.remove(Path(list(conf_df['temp_directory'])[0]+\"/\"+lang+\"_subtitle_tmp.srt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translate_subtitles(connection, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to try\n",
    "def translate_threads(_text,_lang):\n",
    "    transcription_translated = translate_from_en(_text,_lang)\n",
    "    print(transcription_translated[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_transcriptions(_conn, _videoid):\n",
    "    \"\"\"Function to translate the transcriptions in English \n",
    "       to all the languages predefined in the configuration\n",
    "    \n",
    "    Keyword arguments:\n",
    "    _conn: connection to the database\n",
    "    _videoid: Id of the video to translate\n",
    "    Return: Nothing\n",
    "    \"\"\"\n",
    "    \n",
    "    if _conn.is_connected():\n",
    "\n",
    "        cursor_conf = connection.cursor(buffered=True)\n",
    "\n",
    "        query_conf = \"\"\"SELECT languages_subtitles, temp_directory \n",
    "                        FROM ironrep.configuration\n",
    "                        LIMIT 1;\"\"\"\n",
    "        cursor_conf.execute(query_conf)\n",
    "\n",
    "        conf_table = cursor_conf.fetchall()\n",
    "        conf_df = pd.DataFrame(conf_table)\n",
    "        conf_df.columns = [i[0] for i in cursor_conf.description]\n",
    "\n",
    "        cursor = connection.cursor(buffered=True)\n",
    "        query = \"\"\"SELECT videoid, languageid, transcription\n",
    "                    FROM ironrep.transcriptions\n",
    "                    WHERE videoid = %s and languageid = %s\"\"\"\n",
    "        val = [int(_videoid),str('en')]\n",
    "        cursor.execute(query,val)\n",
    "        \n",
    "        trans_table = cursor.fetchall()\n",
    "        if (len(trans_table)>0):                   \n",
    "            #We discard 'en' language since this approach will work from English, not multilingual option.\n",
    "            for lang in [language for languages in conf_df['languages_subtitles'].str.split(',') for language in languages if language != 'en']:\n",
    "                transcription_translated = ''\n",
    "                for transcript in trans_table:\n",
    "                    transcription_translated = translate_from_en(transcript[2],lang)                               \n",
    "                    result_sql = insert_data_sql(connection,'transcription', _videoid, lang, transcription_translated)\n",
    "        else:\n",
    "            print('No video transcription to translate')\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translate_transcriptions(connection,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_keywords(_conn, _videoid):\n",
    "    \"\"\"Function to translate the keywords in English \n",
    "       to all the languages predefined in the configuration\n",
    "    \n",
    "    Keyword arguments:\n",
    "    _conn: connection to the database\n",
    "    _videoid: Id of the video to translate\n",
    "    Return: Nothing\n",
    "    \"\"\"\n",
    "    \n",
    "    if _conn.is_connected():\n",
    "\n",
    "        cursor_conf = connection.cursor(buffered=True)\n",
    "\n",
    "        query_conf = \"\"\"SELECT languages_subtitles, temp_directory \n",
    "                        FROM ironrep.configuration\n",
    "                        LIMIT 1;\"\"\"\n",
    "        cursor_conf.execute(query_conf)\n",
    "\n",
    "        conf_table = cursor_conf.fetchall()\n",
    "        conf_df = pd.DataFrame(conf_table)\n",
    "        conf_df.columns = [i[0] for i in cursor_conf.description]\n",
    "\n",
    "        cursor = connection.cursor(buffered=True)\n",
    "        query = \"\"\"SELECT videoid, languageid, keywords\n",
    "                    FROM ironrep.keywords\n",
    "                    WHERE videoid = %s and languageid = %s\"\"\"\n",
    "        val = [int(_videoid),str('en')]\n",
    "        cursor.execute(query,val)\n",
    "        \n",
    "        keyw_table = cursor.fetchall()\n",
    "        if (len(keyw_table)>0):      \n",
    "            transcription_translated = ''\n",
    "\n",
    "            #We discard 'en' language since this approach will work from English, not multilingual option.\n",
    "            for lang in [language for languages in conf_df['languages_subtitles'].str.split(',') for language in languages if language != 'en']:\n",
    "                for keyw in keyw_table:\n",
    "                    keyw_translated = translate_from_en(keyw[2],lang)                               \n",
    "                    result_sql = insert_data_sql(connection,'keywords', _videoid, lang, keyw_translated)\n",
    "        else:\n",
    "            print('No video transcription to translate')\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translate_keywords(connection,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_summary(_conn, _videoid):\n",
    "    \"\"\"Function to translate the keywords in English \n",
    "       to all the languages predefined in the configuration\n",
    "    \n",
    "    Keyword arguments:\n",
    "    _conn: connection to the database\n",
    "    _videoid: Id of the video to translate\n",
    "    Return: Nothing\n",
    "    \"\"\"\n",
    "    \n",
    "    if _conn.is_connected():\n",
    "\n",
    "        cursor_conf = connection.cursor(buffered=True)\n",
    "\n",
    "        query_conf = \"\"\"SELECT languages_subtitles, temp_directory \n",
    "                        FROM ironrep.configuration\n",
    "                        LIMIT 1;\"\"\"\n",
    "        cursor_conf.execute(query_conf)\n",
    "\n",
    "        conf_table = cursor_conf.fetchall()\n",
    "        conf_df = pd.DataFrame(conf_table)\n",
    "        conf_df.columns = [i[0] for i in cursor_conf.description]\n",
    "\n",
    "        cursor = connection.cursor(buffered=True)\n",
    "        query = \"\"\"SELECT videoid, languageid, summary\n",
    "                    FROM ironrep.summaries\n",
    "                    WHERE videoid = %s and languageid = %s\"\"\"\n",
    "        val = [int(_videoid),str('en')]\n",
    "        cursor.execute(query,val)\n",
    "        \n",
    "        summ_table = cursor.fetchall()\n",
    "        if (len(summ_table)>0):      \n",
    "            tsummary_translated = ''\n",
    "\n",
    "            #We discard 'en' language since this approach will work from English, not multilingual option.\n",
    "            for lang in [language for languages in conf_df['languages_subtitles'].str.split(',') for language in languages if language != 'en']:\n",
    "                for summ in summ_table:\n",
    "                    summ_translated = translate_from_en(summ[2],lang)                               \n",
    "                    result_sql = insert_data_sql(connection,'summary', _videoid, lang, summ_translated)\n",
    "        else:\n",
    "            print('No video transcription to translate')\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_summary(connection, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_player(_conn,_videoid, _langid, _position = 0):\n",
    "    \"\"\"Function to launch the video with subtitles\n",
    "    \n",
    "    Keyword arguments:\n",
    "    _conn: connection object\n",
    "    _videoid: the id of the video\n",
    "    _langid: the id of the language to use for the subtitles\n",
    "    _position: time in seconds to start the video\n",
    "    Return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor = _conn.cursor() \n",
    "    query = \"\"\"SELECT video_player, temp_directory\n",
    "                        FROM ironrep.configuration \n",
    "                        LIMIT 1;\"\"\"\n",
    "\n",
    "    cursor.execute(query)\n",
    "    conf_table = cursor.fetchall()\n",
    "    conf_df = pd.DataFrame(conf_table)\n",
    "    conf_df.columns = [i[0] for i in cursor.description]\n",
    "\n",
    "    query = \"\"\"SELECT subtitles\n",
    "                    FROM ironrep.subtitles\n",
    "                WHERE videoid = %s\n",
    "                    AND languageid = %s\"\"\"\n",
    "    val = [int(_videoid), _langid]\n",
    "    cursor.execute(query, val)    \n",
    "    subt_table = cursor.fetchall()\n",
    "    if (len(subt_table)>0):\n",
    "        subt_df = pd.DataFrame(subt_table)\n",
    "        subt_df.columns = [i[0] for i in cursor.description]\n",
    "\n",
    "        with open(Path(list(conf_df['temp_directory'])[0]+\"/play_subtitle.srt\"), \"w+\") as f:\n",
    "                f.write(list(subt_df['subtitles'])[0])\n",
    "\n",
    "        query = \"\"\"SELECT video_path\n",
    "                    FROM ironrep.videos\n",
    "                    WHERE id = %s\"\"\"\n",
    "        val = [int(_videoid)]\n",
    "        cursor.execute(query, val)\n",
    "        video_table = cursor.fetchall()\n",
    "        video_df = pd.DataFrame(video_table)\n",
    "        video_df.columns = [i[0] for i in cursor.description]\n",
    "\n",
    "        os.system(list(conf_df['video_player'])[0].replace('{videoparam}',list(video_df['video_path'])[0]).replace('{subtitleparam}',list(conf_df['temp_directory'])[0]+\"/play_subtitle.srt\").replace('{positionparam}',str(_position)))\n",
    "    else:\n",
    "         print(f'No subtitles found in language {_langid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video_player(connection, 20, 'en', 8318)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_pos_video(_subitles,_text):\n",
    "    \"\"\"Function to locate the positions of the subtitles\n",
    "       where the text to search is located.\n",
    "       This function will use to find text inside a video\n",
    "    \n",
    "    Keyword arguments:\n",
    "    _subtitles: the subtitles of the video\n",
    "    _text: text to find\n",
    "    Return: a list of tuples with the positition (seconds) and the time\n",
    "    \"\"\"\n",
    "    \n",
    "    pos_find = [re.findall('(\\d{2}:\\d{2}:\\d{2},\\d{3})',_subitles[:i.start()])[-2].split(':') for i in re.finditer(_text.lower(), _subitles.lower())]\n",
    "    positions_final = [(int(pos[0])*3600+int(pos[1])*60+int(float(pos[2].replace(',','.'))),':'.join(pos)) for pos in pos_find]\n",
    "    return positions_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#transcribe(connection,'/home/roque/01. IronHack/00. Data Analytics/01. Course/46. Week 18 - Day 1/recordings/GMT20230103-174702_Recording_1920x1080.mp4')\n",
    "#transcribe(connection,'/home/roque/01. IronHack/00. Data Analytics/01. Course/47. Week 18 - Day 2/recordings/GMT20230105-174236_Recording_1920x1080.mp4')\n",
    "#transcribe(connection,'/home/roque/01. IronHack/00. Data Analytics/01. Course/48. Week 18 - Day 3/recordings/GMT20230107-095007_Recording_1920x1080.mp4')\n",
    "#transcribe(connection,'/home/roque/01. IronHack/00. Data Analytics/01. Course/48. Week 18 - Day 3/recordings/GMT20230107-144617_Recording_1920x1080.mp4')\n",
    "#transcribe(connection,'/home/roque/01. IronHack/00. Data Analytics/01. Course/49. Week 19 - Day 1/recordings/GMT20230110-174656_Recording_1920x1080.mp4')\n",
    "#transcribe(connection,'/home/roque/01. IronHack/00. Data Analytics/01. Course/50. Week 19 - Day 2/recordings/GMT20230112-174421_Recording_1920x1080.mp4')\n",
    "#transcribe(connection,'/home/roque/01. IronHack/00. Data Analytics/01. Course/51. Week 19 - Day 3/recordings/GMT20230114-095105_Recording_1920x1080.mp4')\n",
    "#transcribe(connection,'/home/roque/01. IronHack/00. Data Analytics/01. Course/52. Week 20 - Day 1/recordings/GMT20230117-174400_Recording_1920x1080.mp4')\n",
    "transcribe(connection,'/home/roque/01. IronHack/00. Data Analytics/01. Course/53. Week 20 - Day 2/recordings/GMT20230119-174330_Recording_1920x1080.mp4')\n",
    "transcribe(connection,'/home/roque/01. IronHack/00. Data Analytics/01. Course/55. Week 21 - Day 1/recordings/GMT20230124-175225_Recording_1920x1080.mp4')\n",
    "transcribe(connection,'/home/roque/01. IronHack/00. Data Analytics/01. Course/56. Week 21 - Day 2/recordings/GMT20230126-174322_Recording_1920x1080.mp4')\n",
    "transcribe(connection,'/home/roque/01. IronHack/00. Data Analytics/01. Course/56. Week 21 - Day 2/recordings/time_series.mp4')\n",
    "transcribe(connection,'/home/roque/01. IronHack/00. Data Analytics/01. Course/57. Week 21 - Day 3/recordings/GMT20230128-095524_Recording_1920x1080.mp4')\n",
    "transcribe(connection,'/home/roque/01. IronHack/00. Data Analytics/01. Course/58. Week 22 - Day 1/recordings/GMT20230131-180216_Recording_1920x1080.mp4')\n",
    "transcribe(connection,'/home/roque/01. IronHack/00. Data Analytics/01. Course/59. Week 22 - Day 2/recordings/GMT20230202-174048_Recording_1920x1080.mp4')\n",
    "transcribe(connection,'/home/roque/01. IronHack/00. Data Analytics/01. Course/59. Week 22 - Day 2/recordings/GMT20230202-194534_Recording_1920x1080.mp4')\n",
    "transcribe(connection,'/home/roque/01. IronHack/00. Data Analytics/01. Course/62. Week 23 - Day 2/recordings/GMT20221208-174524_Recording_1920x1080.mp4')\n",
    "transcribe(connection,'/home/roque/01. IronHack/00. Data Analytics/01. Course/63. Week 23 - Day 3/recordings/GMT20220730-085632_Recording_1920x1080.mp4')\n",
    "\n",
    "#translate_subtitles(connection, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "# TODO: Try with a larger text\n",
    "\n",
    "# python -m spacy download en_core_web_sm #eficency\n",
    "# python -m spacy download en_core_web_trf #accuracy\n",
    "\n",
    "import spacy\n",
    "import en_core_web_trf\n",
    "#import en_core_web_sm\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import spacy_transformers\n",
    "from string import punctuation\n",
    "from heapq import nlargest\n",
    "\n",
    "def summarize(text, per):\n",
    "    #nlp = spacy.load('en_core_web_trf')\n",
    "    nlp = en_core_web_trf.load()\n",
    "    doc= nlp(text)\n",
    "    tokens=[token.text for token in doc]\n",
    "    word_frequencies={}\n",
    "    for word in doc:\n",
    "        if word.text.lower() not in list(STOP_WORDS):\n",
    "            if word.text.lower() not in punctuation:\n",
    "                if word.text not in word_frequencies.keys():\n",
    "                    word_frequencies[word.text] = 1\n",
    "                else:\n",
    "                    word_frequencies[word.text] += 1\n",
    "    max_frequency=max(word_frequencies.values())\n",
    "    for word in word_frequencies.keys():\n",
    "        word_frequencies[word]=word_frequencies[word]/max_frequency\n",
    "    sentence_tokens= [sent for sent in doc.sents]\n",
    "    sentence_scores = {}\n",
    "    for sent in sentence_tokens:\n",
    "        for word in sent:\n",
    "            if word.text.lower() in word_frequencies.keys():\n",
    "                if sent not in sentence_scores.keys():                            \n",
    "                    sentence_scores[sent]=word_frequencies[word.text.lower()]\n",
    "                else:\n",
    "                    sentence_scores[sent]+=word_frequencies[word.text.lower()]\n",
    "    select_length=int(len(sentence_tokens)*per)\n",
    "    summary=nlargest(select_length, sentence_scores,key=sentence_scores.get)\n",
    "    final_summary=[word.text for word in summary]\n",
    "    summary=''.join(final_summary)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(result['text'], 0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c2f1846f3955305d6cdcd7be5897be31bd89b0ce061940c94fabaf8ec721e2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
