{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad1aa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "518f7903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roque/01. IronHack/00. Data Analytics/01. Course/63. Week 23 - Day 3/git/final-project-bootcamp/.venv/lib/python3.9/site-packages/whisper/transcribe.py:79: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'write'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mdata/test.txt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw+\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      6\u001b[0m     f\u001b[39m.\u001b[39mwrite(result[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m----> 7\u001b[0m subtitle \u001b[39m=\u001b[39m whisper\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mWriteSRT\u001b[39m.\u001b[39;49mwrite_result(\u001b[39mself\u001b[39;49m\u001b[39m=\u001b[39;49mwhisper,result\u001b[39m=\u001b[39;49mresult,file\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtest.srt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      8\u001b[0m \u001b[39mlen\u001b[39m(subtitle)\n",
      "File \u001b[0;32m~/01. IronHack/00. Data Analytics/01. Course/63. Week 23 - Day 3/git/final-project-bootcamp/.venv/lib/python3.9/site-packages/whisper/utils.py:108\u001b[0m, in \u001b[0;36mWriteSRT.write_result\u001b[0;34m(self, result, file)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrite_result\u001b[39m(\u001b[39mself\u001b[39m, result: \u001b[39mdict\u001b[39m, file: TextIO):\n\u001b[1;32m    106\u001b[0m     \u001b[39mfor\u001b[39;00m i, segment \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(result[\u001b[39m\"\u001b[39m\u001b[39msegments\u001b[39m\u001b[39m\"\u001b[39m], start\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m    107\u001b[0m         \u001b[39m# write srt lines\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m         \u001b[39mprint\u001b[39;49m(\n\u001b[1;32m    109\u001b[0m             \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m    110\u001b[0m             \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mformat_timestamp(segment[\u001b[39m'\u001b[39;49m\u001b[39mstart\u001b[39;49m\u001b[39m'\u001b[39;49m],\u001b[39m \u001b[39;49malways_include_hours\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\u001b[39m \u001b[39;49mdecimal_marker\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m}\u001b[39;49;00m\u001b[39m --> \u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m    111\u001b[0m             \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mformat_timestamp(segment[\u001b[39m'\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m'\u001b[39;49m],\u001b[39m \u001b[39;49malways_include_hours\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\u001b[39m \u001b[39;49mdecimal_marker\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m}\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m    112\u001b[0m             \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00msegment[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mstrip()\u001b[39m.\u001b[39;49mreplace(\u001b[39m'\u001b[39;49m\u001b[39m-->\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m->\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m}\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    113\u001b[0m             file\u001b[39m=\u001b[39;49mfile,\n\u001b[1;32m    114\u001b[0m             flush\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    115\u001b[0m         )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'write'"
     ]
    }
   ],
   "source": [
    "# speech\n",
    "model = whisper.load_model(\"tiny\")\n",
    "result = model.transcribe(\"data/test.mp3\")\n",
    "#print(result[\"text\"])\n",
    "with open(\"data/test.txt\", \"w+\") as f:\n",
    "    f.write(result[\"text\"])\n",
    "subtitle = whisper.utils.WriteSRT.write_result(self=whisper,result=result,file='test.srt')\n",
    "len(subtitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc7dc24e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'write_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m write_result(subtitles)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'write_result' is not defined"
     ]
    }
   ],
   "source": [
    "write_result(subtitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "234d2221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roque/01. IronHack/00. Data Analytics/01. Course/63. Week 23 - Day 3/git/final-project-bootcamp/.venv/lib/python3.9/site-packages/whisper/transcribe.py:79: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "# song\n",
    "model = whisper.load_model(\"tiny\")\n",
    "result = model.transcribe(\"data/song.mp3\")\n",
    "#print(result[\"text\"])\n",
    "with open(\"data/song.txt\", \"w+\") as f:\n",
    "    f.write(result[\"text\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "942876d5",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OpenAI Whisper command line\n",
    "    \n",
    "# convert mp3 to wav file\n",
    "%timeit subprocess.call(['whisper', 'data/test.mp3', '--model', 'tiny.en', '-o', 'data', '-f', 'txt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'speech_recognition'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mspeech_recognition\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msr\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'speech_recognition'"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_FILE='data/test.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sr.AudioFile(AUDIO_FILE) as source:\n",
    "    audio = r.record(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.recognize_whisper(audio, model='tiny.en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"recognizer_instance.recognize_whisper(audio_data: AudioData, model: str=\"base\", show_dict: bool=False, load_options: Dict[Any, Any]=None, language:Optional[str]=None, translate:bool=False, **transcribe_options):\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_recognition.Microphone()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca0e965b",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ad57ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting video\n",
    "\n",
    "#Importing library and thir function\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "#reading from audio mp3 file\n",
    "sound = AudioSegment.from_mp3(\"/content/Audio/song_with_silence.mp3\")\n",
    "\n",
    "# spliting audio files\n",
    "audio_chunks = split_on_silence(sound, min_silence_len=500, silence_thresh=-40 )\n",
    "\n",
    "#loop is used to iterate over the output list\n",
    "for i, chunk in enumerate(audio_chunks):\n",
    "   output_file = \"/content/Audio/output/chunk{0}.mp3\".format(i)\n",
    "   print(\"Exporting file\", output_file)\n",
    "   chunk.export(output_file, format=\"mp3\")\n",
    "\n",
    "# chunk files saved as Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66617d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "audio = AudioSegment.from_file(\"data/test.mp4\", format=\"mp4\")\n",
    "\n",
    "chunks = split_on_silence(audio, \n",
    "                         keep_silence=30000, \n",
    "                         min_silence_len=200, \n",
    "                         silence_thresh=-30)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk.export(f\"data/Chunks/output_{i}.mp3\", format=\"mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d5887662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 8.34 µs\n",
      "CPU times: user 9 µs, sys: 0 ns, total: 9 µs\n",
      "Wall time: 16.2 µs\n",
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.96 µs\n",
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 7.15 µs\n",
      "CPU times: user 8 µs, sys: 0 ns, total: 8 µs\n",
      "Wall time: 12.2 µs\n",
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 12.4 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roque/01. IronHack/00. Data Analytics/01. Course/63. Week 23 - Day 3/git/final-project-bootcamp/.venv/lib/python3.9/site-packages/whisper/transcribe.py:79: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/roque/01. IronHack/00. Data Analytics/01. Course/63. Week 23 - Day 3/git/final-project-bootcamp/.venv/lib/python3.9/site-packages/whisper/transcribe.py:79: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/roque/01. IronHack/00. Data Analytics/01. Course/63. Week 23 - Day 3/git/final-project-bootcamp/.venv/lib/python3.9/site-packages/whisper/transcribe.py:79: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/roque/01. IronHack/00. Data Analytics/01. Course/63. Week 23 - Day 3/git/final-project-bootcamp/.venv/lib/python3.9/site-packages/whisper/transcribe.py:79: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/roque/01. IronHack/00. Data Analytics/01. Course/63. Week 23 - Day 3/git/final-project-bootcamp/.venv/lib/python3.9/site-packages/whisper/transcribe.py:79: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/roque/01. IronHack/00. Data Analytics/01. Course/63. Week 23 - Day 3/git/final-project-bootcamp/.venv/lib/python3.9/site-packages/whisper/transcribe.py:79: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/roque/01. IronHack/00. Data Analytics/01. Course/63. Week 23 - Day 3/git/final-project-bootcamp/.venv/lib/python3.9/site-packages/whisper/transcribe.py:79: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/roque/01. IronHack/00. Data Analytics/01. Course/63. Week 23 - Day 3/git/final-project-bootcamp/.venv/lib/python3.9/site-packages/whisper/transcribe.py:79: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 0 ns, total: 7 µs\n",
      "Wall time: 15 µs\n",
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nsegments_final = repairTranscriptSegments([seg for segment in segments for seg in segment],40)\\n#segments = result[\\'segments\\']\\n\\nfor segment in segments_final:\\n    startTime = str(0)+str(timedelta(seconds=int(segment[\\'start\\'])))+\\',000\\'\\n    endTime = str(0)+str(timedelta(seconds=int(segment[\\'end\\'])))+\\',000\\'\\n    text = segment[\\'text\\']\\n    segmentId = segment[\\'id\\']+1\\n    segment = f\"{segmentId}\\n{startTime} --> {endTime}\\n{text[1:] if text[0] == \\' \\' else text}\\n\\n\"\\n\\n    srtFilename = os.path.join(r\"data\", \"test.srt\")\\n    with open(srtFilename, \\'a\\', encoding=\\'utf-8\\') as srtFile:\\n        srtFile.write(segment)\\n'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "import whisper\n",
    "import os\n",
    "from datetime import timedelta\n",
    "ifrom threading import Thread\n",
    "\n",
    "%time\n",
    "sound = AudioSegment.from_file(\"data/test.mp4\", format=\"mp4\")\n",
    "chunks = split_on_silence(\n",
    "    sound,\n",
    "\n",
    "    # split on silences longer than 1000ms (1 sec)\n",
    "    min_silence_len=1000,\n",
    "\n",
    "    # anything under -16 dBFS is considered silence\n",
    "    silence_thresh=-30, \n",
    "\n",
    "    # keep 200 ms of leading/trailing silence\n",
    "    keep_silence=200\n",
    ")\n",
    "%time\n",
    "# now recombine the chunks so that the parts are at least 30 sec long\n",
    "target_length = 30 * 1000\n",
    "output_chunks = [chunks[0]]\n",
    "for chunk in chunks[1:]:\n",
    "    if len(output_chunks[-1]) < target_length:\n",
    "        output_chunks[-1] += chunk\n",
    "    else:\n",
    "        # if the last output chunk is longer than the target length,\n",
    "        # we can start a new one\n",
    "        output_chunks.append(chunk)\n",
    "\n",
    "# now your have chunks that are bigger than 90 seconds (except, possibly the last one)\n",
    "%time\n",
    "\n",
    "n_threads = 8\n",
    "threads = []\n",
    "\n",
    "for i, chunk in enumerate(output_chunks):\n",
    "    t = Thread(target=chunk.export(f\"data/Chunks/output_{i}.mp3\", format=\"mp3\"))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "%time\n",
    "# Get a list of all the audio files in the \"data/Chunks/\" folder\n",
    "audio_files = [f for f in sorted(os.listdir(\"data/Chunks/\")) if f.endswith('.mp3')]\n",
    "%time\n",
    "# Initialize an empty list to store the transcriptions\n",
    "transcriptions = []\n",
    "segments = []\n",
    "\n",
    "model = whisper.load_model(\"tiny.en\",device='cpu')\n",
    "%time\n",
    "# Loop over all the audio files in the \"data/Chunks/\" folder\n",
    "for audio_file in audio_files:\n",
    "    audio_file_path = os.path.join(\"data/Chunks/\", audio_file)\n",
    "    result = model.transcribe(audio_file_path)\n",
    "    #transcription = str(result)\n",
    "    transcriptions.append(result['text'])\n",
    "    #print(len(result['segments']))\n",
    "    segments.append([res for res in result['segments']])\n",
    "\n",
    "    #os.remove(audio_file_path)\n",
    "%time\n",
    "with open(\"data/test.txt\", \"w+\") as f:\n",
    "    f.write(' '.join(transcriptions))\n",
    "%time\n",
    "# subtitles\n",
    "# TODO:Need to fix\n",
    "\"\"\"\n",
    "segments_final = repairTranscriptSegments([seg for segment in segments for seg in segment],40)\n",
    "#segments = result['segments']\n",
    "\n",
    "for segment in segments_final:\n",
    "    startTime = str(0)+str(timedelta(seconds=int(segment['start'])))+',000'\n",
    "    endTime = str(0)+str(timedelta(seconds=int(segment['end'])))+',000'\n",
    "    text = segment['text']\n",
    "    segmentId = segment['id']+1\n",
    "    segment = f\"{segmentId}\\n{startTime} --> {endTime}\\n{text[1:] if text[0] == ' ' else text}\\n\\n\"\n",
    "\n",
    "    srtFilename = os.path.join(r\"data\", \"test.srt\")\n",
    "    with open(srtFilename, 'a', encoding='utf-8') as srtFile:\n",
    "        srtFile.write(segment)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f1e440da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roque/01. IronHack/00. Data Analytics/01. Course/63. Week 23 - Day 3/git/final-project-bootcamp/.venv/lib/python3.9/site-packages/whisper/transcribe.py:79: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 0, 'seek': 0, 'start': 0.0, 'end': 3.4, 'text': ' And I will share my screen.', 'tokens': [843, 314, 481, 2648, 616, 3159, 13], 'temperature': 0.0, 'avg_logprob': -0.2766423658891158, 'compression_ratio': 1.673913043478261, 'no_speech_prob': 0.07262368500232697}, {'id': 1, 'seek': 0, 'start': 3.4, 'end': 6.5200000000000005, 'text': ' So basically one of the most asked questions', 'tokens': [1406, 6209, 530, 286, 262, 749, 1965, 2683], 'temperature': 0.0, 'avg_logprob': -0.2766423658891158, 'compression_ratio': 1.673913043478261, 'no_speech_prob': 0.07262368500232697}, {'id': 2, 'seek': 0, 'start': 6.5200000000000005, 'end': 8.4, 'text': ' for this next six months arc.', 'tokens': [329, 428, 1306, 2237, 1933, 10389, 13], 'temperature': 0.0, 'avg_logprob': -0.2766423658891158, 'compression_ratio': 1.673913043478261, 'no_speech_prob': 0.07262368500232697}, {'id': 3, 'seek': 0, 'start': 8.4, 'end': 9.4, 'text': ' Can you all see my screen?', 'tokens': [1680, 345, 477, 766, 616, 3159, 30], 'temperature': 0.0, 'avg_logprob': -0.2766423658891158, 'compression_ratio': 1.673913043478261, 'no_speech_prob': 0.07262368500232697}, {'id': 4, 'seek': 0, 'start': 9.4, 'end': 11.200000000000001, 'text': \" And can you incase you don't?\", 'tokens': [843, 460, 345, 753, 589, 345, 836, 470, 30], 'temperature': 0.0, 'avg_logprob': -0.2766423658891158, 'compression_ratio': 1.673913043478261, 'no_speech_prob': 0.07262368500232697}, {'id': 5, 'seek': 0, 'start': 11.200000000000001, 'end': 13.72, 'text': ' Let me know or just write in the chat.', 'tokens': [3914, 502, 760, 393, 655, 3551, 287, 262, 8537, 13], 'temperature': 0.0, 'avg_logprob': -0.2766423658891158, 'compression_ratio': 1.673913043478261, 'no_speech_prob': 0.07262368500232697}, {'id': 6, 'seek': 0, 'start': 13.72, 'end': 15.88, 'text': ' Otherwise, are you start?', 'tokens': [15323, 11, 389, 345, 923, 30], 'temperature': 0.0, 'avg_logprob': -0.2766423658891158, 'compression_ratio': 1.673913043478261, 'no_speech_prob': 0.07262368500232697}, {'id': 7, 'seek': 0, 'start': 15.88, 'end': 18.6, 'text': ' OK, so the agenda for my presentation', 'tokens': [7477, 11, 523, 262, 8666, 329, 616, 10470], 'temperature': 0.0, 'avg_logprob': -0.2766423658891158, 'compression_ratio': 1.673913043478261, 'no_speech_prob': 0.07262368500232697}, {'id': 8, 'seek': 0, 'start': 18.6, 'end': 21.52, 'text': ' is what do I need to start the course?', 'tokens': [318, 644, 466, 314, 761, 284, 923, 262, 1781, 30], 'temperature': 0.0, 'avg_logprob': -0.2766423658891158, 'compression_ratio': 1.673913043478261, 'no_speech_prob': 0.07262368500232697}, {'id': 9, 'seek': 0, 'start': 21.52, 'end': 24.0, 'text': ' Then what should I expect in the following days?', 'tokens': [3244, 644, 815, 314, 1607, 287, 262, 1708, 1528, 30], 'temperature': 0.0, 'avg_logprob': -0.2766423658891158, 'compression_ratio': 1.673913043478261, 'no_speech_prob': 0.07262368500232697}, {'id': 10, 'seek': 0, 'start': 24.0, 'end': 27.240000000000002, 'text': ' What should I do to successfully complete the bootcamp?', 'tokens': [1867, 815, 314, 466, 284, 7675, 1844, 262, 6297, 16544, 30], 'temperature': 0.0, 'avg_logprob': -0.2766423658891158, 'compression_ratio': 1.673913043478261, 'no_speech_prob': 0.07262368500232697}, {'id': 11, 'seek': 0, 'start': 27.240000000000002, 'end': 29.76, 'text': ' And of course, we all want you to complete the bootcamp', 'tokens': [843, 286, 1781, 11, 356, 477, 765, 345, 284, 1844, 262, 6297, 16544], 'temperature': 0.0, 'avg_logprob': -0.2766423658891158, 'compression_ratio': 1.673913043478261, 'no_speech_prob': 0.07262368500232697}, {'id': 12, 'seek': 2976, 'start': 29.76, 'end': 32.64, 'text': ' successful, who will be my point of contact,', 'tokens': [4388, 11, 508, 481, 307, 616, 966, 286, 2800, 11], 'temperature': 0.0, 'avg_logprob': -0.37242428461710614, 'compression_ratio': 1.1153846153846154, 'no_speech_prob': 3.35878134194445e-08}, {'id': 13, 'seek': 3264, 'start': 32.64, 'end': 53.64, 'text': ' and then you will meet your teaching team.', 'tokens': [290, 788, 345, 481, 1826, 534, 7743, 1074, 13], 'temperature': 0.0, 'avg_logprob': -0.569963968717135, 'compression_ratio': 0.9333333333333333, 'no_speech_prob': 4.0286909097630996e-07}]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(result[\u001b[39m'\u001b[39m\u001b[39msegments\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m \u001b[39m#[segments.append(res) for res in len(result['segments'])]\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m segments\u001b[39m.\u001b[39mappend([res \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m \u001b[39mlen\u001b[39m(result[\u001b[39m'\u001b[39m\u001b[39msegments\u001b[39m\u001b[39m'\u001b[39m])])\n\u001b[1;32m     11\u001b[0m \u001b[39m#os.remove(audio_file_path)\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Loop over all the audio files in the \"data/Chunks/\" folder\n",
    "for audio_file in audio_files:\n",
    "    audio_file_path = os.path.join(\"data/Chunks/\", audio_file)\n",
    "    result = model.transcribe(audio_file_path)\n",
    "    #transcription = str(result)\n",
    "    #transcriptions.append(result['text'])\n",
    "    print(result['segments'])\n",
    "    #[segments.append(res) for res in len(result['segments'])]\n",
    "    segments.append([res for res in len(result['segments'])])\n",
    "\n",
    "    #os.remove(audio_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7df895e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#' '.join(transcriptions)\n",
    "seg_final = [seg for segment in segments for seg in segment]\n",
    "len(seg_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bfe37123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repairTranscriptSegments(transcript, chunkSeconds):\n",
    "    \"\"\"\n",
    "        We are repairing the timeline here.\n",
    "        If we are just transcibing, repair of the timeline is not needed because\n",
    "        we would simply not use the timeline information but if we want to develop\n",
    "        an SRT, VTT or some other tool that makes use of timing, this is required.\n",
    "        We expect that for every new audio chunk, the segment information will be\n",
    "        re-initialized.  We concatenated each chunk's segments and determining an\n",
    "        offset amount for each chunk, then adjust the \"start\" and \"end\" segments,\n",
    "        so the timestamps are contiguous.\n",
    "        \"chunkSeconds\" is the length of each chunk, so we know that the segment[\"end\"]\n",
    "        cant be beyond this. After repairing the timeline, from the concatenated chunks\n",
    "        we can use the built-in functions to write TEXT, SRT and VTT files.\n",
    "    \"\"\"\n",
    "    \n",
    "    chunkCount = 0\n",
    "    for segIndex, segment in enumerate(transcript):\n",
    "        if (segment[\"id\"] == 0):\n",
    "            chunkCount += 1\n",
    "            if (chunkCount > 1):\n",
    "                prevSegment = transcript[segIndex-1] # look back to previous segment\n",
    "                if (prevSegment[\"end\"] > chunkSeconds): # impossible to be greater than chunk length\n",
    "                    transcript[segIndex-1][\"end\"] = chunkSeconds\n",
    "\n",
    "    chunkCount = 0 # re-initialize\n",
    "    adjustTime = 0.0\n",
    "    for segIndex, segment in enumerate(transcript):\n",
    "        segID = segment[\"id\"]\n",
    "        if (segID == 0):\n",
    "            chunkCount += 1\n",
    "            adjustTime  = ((chunkCount - 1) * chunkSeconds)\n",
    "                \n",
    "#        if (segID == 0)   : segment[\"text\"] += \"@@@@@\" # TESTING: This is a marker so we know where each new segment is located\n",
    "        segment[\"start\"] += adjustTime\n",
    "        segment[\"end\"]   += adjustTime\n",
    "        segment[\"id\"]     = segIndex # repair the sequence, so the IDs are now contiguous\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8938a3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'seek': 0,\n",
       "  'start': 0.0,\n",
       "  'end': 3.4,\n",
       "  'text': ' And I will share my screen.',\n",
       "  'tokens': [843, 314, 481, 2648, 616, 3159, 13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2766423658891158,\n",
       "  'compression_ratio': 1.673913043478261,\n",
       "  'no_speech_prob': 0.07262368500232697},\n",
       " {'id': 1,\n",
       "  'seek': 0,\n",
       "  'start': 3.4,\n",
       "  'end': 6.5200000000000005,\n",
       "  'text': ' So basically one of the most asked questions',\n",
       "  'tokens': [1406, 6209, 530, 286, 262, 749, 1965, 2683],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2766423658891158,\n",
       "  'compression_ratio': 1.673913043478261,\n",
       "  'no_speech_prob': 0.07262368500232697},\n",
       " {'id': 2,\n",
       "  'seek': 0,\n",
       "  'start': 6.5200000000000005,\n",
       "  'end': 8.4,\n",
       "  'text': ' for this next six months arc.',\n",
       "  'tokens': [329, 428, 1306, 2237, 1933, 10389, 13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2766423658891158,\n",
       "  'compression_ratio': 1.673913043478261,\n",
       "  'no_speech_prob': 0.07262368500232697},\n",
       " {'id': 3,\n",
       "  'seek': 0,\n",
       "  'start': 8.4,\n",
       "  'end': 9.4,\n",
       "  'text': ' Can you all see my screen?',\n",
       "  'tokens': [1680, 345, 477, 766, 616, 3159, 30],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2766423658891158,\n",
       "  'compression_ratio': 1.673913043478261,\n",
       "  'no_speech_prob': 0.07262368500232697},\n",
       " {'id': 4,\n",
       "  'seek': 0,\n",
       "  'start': 9.4,\n",
       "  'end': 11.200000000000001,\n",
       "  'text': \" And can you incase you don't?\",\n",
       "  'tokens': [843, 460, 345, 753, 589, 345, 836, 470, 30],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2766423658891158,\n",
       "  'compression_ratio': 1.673913043478261,\n",
       "  'no_speech_prob': 0.07262368500232697},\n",
       " {'id': 5,\n",
       "  'seek': 0,\n",
       "  'start': 11.200000000000001,\n",
       "  'end': 13.72,\n",
       "  'text': ' Let me know or just write in the chat.',\n",
       "  'tokens': [3914, 502, 760, 393, 655, 3551, 287, 262, 8537, 13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2766423658891158,\n",
       "  'compression_ratio': 1.673913043478261,\n",
       "  'no_speech_prob': 0.07262368500232697},\n",
       " {'id': 6,\n",
       "  'seek': 0,\n",
       "  'start': 13.72,\n",
       "  'end': 15.88,\n",
       "  'text': ' Otherwise, are you start?',\n",
       "  'tokens': [15323, 11, 389, 345, 923, 30],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2766423658891158,\n",
       "  'compression_ratio': 1.673913043478261,\n",
       "  'no_speech_prob': 0.07262368500232697},\n",
       " {'id': 7,\n",
       "  'seek': 0,\n",
       "  'start': 15.88,\n",
       "  'end': 18.6,\n",
       "  'text': ' OK, so the agenda for my presentation',\n",
       "  'tokens': [7477, 11, 523, 262, 8666, 329, 616, 10470],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2766423658891158,\n",
       "  'compression_ratio': 1.673913043478261,\n",
       "  'no_speech_prob': 0.07262368500232697},\n",
       " {'id': 8,\n",
       "  'seek': 0,\n",
       "  'start': 18.6,\n",
       "  'end': 21.52,\n",
       "  'text': ' is what do I need to start the course?',\n",
       "  'tokens': [318, 644, 466, 314, 761, 284, 923, 262, 1781, 30],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2766423658891158,\n",
       "  'compression_ratio': 1.673913043478261,\n",
       "  'no_speech_prob': 0.07262368500232697},\n",
       " {'id': 9,\n",
       "  'seek': 0,\n",
       "  'start': 21.52,\n",
       "  'end': 24.0,\n",
       "  'text': ' Then what should I expect in the following days?',\n",
       "  'tokens': [3244, 644, 815, 314, 1607, 287, 262, 1708, 1528, 30],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2766423658891158,\n",
       "  'compression_ratio': 1.673913043478261,\n",
       "  'no_speech_prob': 0.07262368500232697},\n",
       " {'id': 10,\n",
       "  'seek': 0,\n",
       "  'start': 24.0,\n",
       "  'end': 27.240000000000002,\n",
       "  'text': ' What should I do to successfully complete the bootcamp?',\n",
       "  'tokens': [1867, 815, 314, 466, 284, 7675, 1844, 262, 6297, 16544, 30],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2766423658891158,\n",
       "  'compression_ratio': 1.673913043478261,\n",
       "  'no_speech_prob': 0.07262368500232697},\n",
       " {'id': 11,\n",
       "  'seek': 0,\n",
       "  'start': 27.240000000000002,\n",
       "  'end': 29.76,\n",
       "  'text': ' And of course, we all want you to complete the bootcamp',\n",
       "  'tokens': [843,\n",
       "   286,\n",
       "   1781,\n",
       "   11,\n",
       "   356,\n",
       "   477,\n",
       "   765,\n",
       "   345,\n",
       "   284,\n",
       "   1844,\n",
       "   262,\n",
       "   6297,\n",
       "   16544],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2766423658891158,\n",
       "  'compression_ratio': 1.673913043478261,\n",
       "  'no_speech_prob': 0.07262368500232697},\n",
       " {'id': 12,\n",
       "  'seek': 2976,\n",
       "  'start': 29.76,\n",
       "  'end': 32.64,\n",
       "  'text': ' successful, who will be my point of contact,',\n",
       "  'tokens': [4388, 11, 508, 481, 307, 616, 966, 286, 2800, 11],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.37242428461710614,\n",
       "  'compression_ratio': 1.1153846153846154,\n",
       "  'no_speech_prob': 3.35878134194445e-08},\n",
       " {'id': 13,\n",
       "  'seek': 3264,\n",
       "  'start': 32.64,\n",
       "  'end': 30,\n",
       "  'text': ' and then you will meet your teaching team.',\n",
       "  'tokens': [290, 788, 345, 481, 1826, 534, 7743, 1074, 13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.569963968717135,\n",
       "  'compression_ratio': 0.9333333333333333,\n",
       "  'no_speech_prob': 4.0286909097630996e-07},\n",
       " {'id': 14,\n",
       "  'seek': 0,\n",
       "  'start': 30.0,\n",
       "  'end': 32.48,\n",
       "  'text': ' So what do I need to start the course, right?',\n",
       "  'tokens': [1406, 644, 466, 314, 761, 284, 923, 262, 1781, 11, 826, 30],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.30523938981313553,\n",
       "  'compression_ratio': 1.7142857142857142,\n",
       "  'no_speech_prob': 0.046364299952983856},\n",
       " {'id': 15,\n",
       "  'seek': 0,\n",
       "  'start': 32.48,\n",
       "  'end': 35.480000000000004,\n",
       "  'text': ' First, very important beyond Slack.',\n",
       "  'tokens': [3274, 11, 845, 1593, 3675, 36256, 13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.30523938981313553,\n",
       "  'compression_ratio': 1.7142857142857142,\n",
       "  'no_speech_prob': 0.046364299952983856},\n",
       " {'id': 16,\n",
       "  'seek': 0,\n",
       "  'start': 35.480000000000004,\n",
       "  'end': 38.519999999999996,\n",
       "  'text': ' I know if you are working with Slack for the first time',\n",
       "  'tokens': [314, 760, 611, 345, 389, 1762, 351, 36256, 329, 262, 717, 640],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.30523938981313553,\n",
       "  'compression_ratio': 1.7142857142857142,\n",
       "  'no_speech_prob': 0.046364299952983856},\n",
       " {'id': 17,\n",
       "  'seek': 0,\n",
       "  'start': 38.519999999999996,\n",
       "  'end': 40.64,\n",
       "  'text': \" in Canada, we're a bit confusing because we are\",\n",
       "  'tokens': [287, 3340, 11, 356, 821, 257, 1643, 15337, 780, 356, 389],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.30523938981313553,\n",
       "  'compression_ratio': 1.7142857142857142,\n",
       "  'no_speech_prob': 0.046364299952983856},\n",
       " {'id': 18,\n",
       "  'seek': 0,\n",
       "  'start': 40.64,\n",
       "  'end': 42.64,\n",
       "  'text': ' working with two different workspace.',\n",
       "  'tokens': [1762, 351, 734, 1180, 44573, 13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.30523938981313553,\n",
       "  'compression_ratio': 1.7142857142857142,\n",
       "  'no_speech_prob': 0.046364299952983856},\n",
       " {'id': 19,\n",
       "  'seek': 0,\n",
       "  'start': 42.64,\n",
       "  'end': 46.04,\n",
       "  'text': ' You have the general workspace, which is the light blue one.',\n",
       "  'tokens': [921,\n",
       "   423,\n",
       "   262,\n",
       "   2276,\n",
       "   44573,\n",
       "   11,\n",
       "   543,\n",
       "   318,\n",
       "   262,\n",
       "   1657,\n",
       "   4171,\n",
       "   530,\n",
       "   13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.30523938981313553,\n",
       "  'compression_ratio': 1.7142857142857142,\n",
       "  'no_speech_prob': 0.046364299952983856},\n",
       " {'id': 20,\n",
       "  'seek': 0,\n",
       "  'start': 46.04,\n",
       "  'end': 48.6,\n",
       "  'text': ' And there you can find every iron hacker ever,',\n",
       "  'tokens': [843, 612, 345, 460, 1064, 790, 6953, 23385, 1683, 11],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.30523938981313553,\n",
       "  'compression_ratio': 1.7142857142857142,\n",
       "  'no_speech_prob': 0.046364299952983856},\n",
       " {'id': 21,\n",
       "  'seek': 0,\n",
       "  'start': 48.6,\n",
       "  'end': 51.44,\n",
       "  'text': ' and also the data pre-work help channel.',\n",
       "  'tokens': [290, 635, 262, 1366, 662, 12, 1818, 1037, 6518, 13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.30523938981313553,\n",
       "  'compression_ratio': 1.7142857142857142,\n",
       "  'no_speech_prob': 0.046364299952983856},\n",
       " {'id': 22,\n",
       "  'seek': 0,\n",
       "  'start': 51.44,\n",
       "  'end': 56.08,\n",
       "  'text': ' And then you already receive the link for the class workspace.',\n",
       "  'tokens': [843, 788, 345, 1541, 3328, 262, 2792, 329, 262, 1398, 44573, 13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.30523938981313553,\n",
       "  'compression_ratio': 1.7142857142857142,\n",
       "  'no_speech_prob': 0.046364299952983856},\n",
       " {'id': 23,\n",
       "  'seek': 0,\n",
       "  'start': 56.08,\n",
       "  'end': 58.8,\n",
       "  'text': \" It's like where all the daily communication takes place.\",\n",
       "  'tokens': [632, 338, 588, 810, 477, 262, 4445, 6946, 2753, 1295, 13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.30523938981313553,\n",
       "  'compression_ratio': 1.7142857142857142,\n",
       "  'no_speech_prob': 0.046364299952983856},\n",
       " {'id': 24,\n",
       "  'seek': 2880,\n",
       "  'start': 58.8,\n",
       "  'end': 60.72,\n",
       "  'text': \" So it's mandatory to join there.\",\n",
       "  'tokens': [1406, 340, 338, 13677, 284, 4654, 612, 13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3565493730398325,\n",
       "  'compression_ratio': 1.3435114503816794,\n",
       "  'no_speech_prob': 1.793522308446427e-08},\n",
       " {'id': 25,\n",
       "  'seek': 2880,\n",
       "  'start': 60.72,\n",
       "  'end': 63.480000000000004,\n",
       "  'text': ' I think not everyone joins by now.',\n",
       "  'tokens': [314, 892, 407, 2506, 15449, 416, 783, 13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3565493730398325,\n",
       "  'compression_ratio': 1.3435114503816794,\n",
       "  'no_speech_prob': 1.793522308446427e-08},\n",
       " {'id': 26,\n",
       "  'seek': 2880,\n",
       "  'start': 63.480000000000004,\n",
       "  'end': 64.84,\n",
       "  'text': \" That's what I saw.\",\n",
       "  'tokens': [1320, 338, 644, 314, 2497, 13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3565493730398325,\n",
       "  'compression_ratio': 1.3435114503816794,\n",
       "  'no_speech_prob': 1.793522308446427e-08},\n",
       " {'id': 27,\n",
       "  'seek': 2880,\n",
       "  'start': 64.84,\n",
       "  'end': 66.96000000000001,\n",
       "  'text': ' If you are struggling, finding the link or struggle,',\n",
       "  'tokens': [1002, 345, 389, 9648, 11, 4917, 262, 2792, 393, 6531, 11],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3565493730398325,\n",
       "  'compression_ratio': 1.3435114503816794,\n",
       "  'no_speech_prob': 1.793522308446427e-08},\n",
       " {'id': 28,\n",
       "  'seek': 3696,\n",
       "  'start': 66.96000000000001,\n",
       "  'end': 60,\n",
       "  'text': ' joining Slack, just erit out to sub',\n",
       "  'tokens': [9679, 36256, 11, 655, 1931, 270, 503, 284, 850],\n",
       "  'temperature': 1.0,\n",
       "  'avg_logprob': -2.738597576434796,\n",
       "  'compression_ratio': 0.813953488372093,\n",
       "  'no_speech_prob': 4.449120388017036e-05},\n",
       " {'id': 29,\n",
       "  'seek': 0,\n",
       "  'start': 60.0,\n",
       "  'end': 71.0,\n",
       "  'text': ' And in the classwork space, you have all your teaching team and all your, then in terms of prework. So prework should be ready by now. If not, please reach out to me.',\n",
       "  'tokens': [843,\n",
       "   287,\n",
       "   262,\n",
       "   1398,\n",
       "   1818,\n",
       "   2272,\n",
       "   11,\n",
       "   345,\n",
       "   423,\n",
       "   477,\n",
       "   534,\n",
       "   7743,\n",
       "   1074,\n",
       "   290,\n",
       "   477,\n",
       "   534,\n",
       "   11,\n",
       "   788,\n",
       "   287,\n",
       "   2846,\n",
       "   286,\n",
       "   662,\n",
       "   1818,\n",
       "   13,\n",
       "   1406,\n",
       "   662,\n",
       "   1818,\n",
       "   815,\n",
       "   307,\n",
       "   3492,\n",
       "   416,\n",
       "   783,\n",
       "   13,\n",
       "   1002,\n",
       "   407,\n",
       "   11,\n",
       "   3387,\n",
       "   3151,\n",
       "   503,\n",
       "   284,\n",
       "   502,\n",
       "   13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2769418443952288,\n",
       "  'compression_ratio': 1.6225490196078431,\n",
       "  'no_speech_prob': 0.0841040313243866},\n",
       " {'id': 30,\n",
       "  'seek': 0,\n",
       "  'start': 71.0,\n",
       "  'end': 81.0,\n",
       "  'text': \" The thing we are so strict on pre-work deadline is at first. It's, you do yourself a favor because if you don't do pre-work, you won't be able to follow the course.\",\n",
       "  'tokens': [383,\n",
       "   1517,\n",
       "   356,\n",
       "   389,\n",
       "   523,\n",
       "   7646,\n",
       "   319,\n",
       "   662,\n",
       "   12,\n",
       "   1818,\n",
       "   12508,\n",
       "   318,\n",
       "   379,\n",
       "   717,\n",
       "   13,\n",
       "   632,\n",
       "   338,\n",
       "   11,\n",
       "   345,\n",
       "   466,\n",
       "   3511,\n",
       "   257,\n",
       "   2661,\n",
       "   780,\n",
       "   611,\n",
       "   345,\n",
       "   836,\n",
       "   470,\n",
       "   466,\n",
       "   662,\n",
       "   12,\n",
       "   1818,\n",
       "   11,\n",
       "   345,\n",
       "   1839,\n",
       "   470,\n",
       "   307,\n",
       "   1498,\n",
       "   284,\n",
       "   1061,\n",
       "   262,\n",
       "   1781,\n",
       "   13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2769418443952288,\n",
       "  'compression_ratio': 1.6225490196078431,\n",
       "  'no_speech_prob': 0.0841040313243866},\n",
       " {'id': 31,\n",
       "  'seek': 2100,\n",
       "  'start': 81.0,\n",
       "  'end': 93.0,\n",
       "  'text': \" Because the course is fast paced and it's very easier for you if you have like the insights on pre-work. On the other side, your teaching team will look through the pre-work and then need to provide some feedback.\",\n",
       "  'tokens': [4362,\n",
       "   262,\n",
       "   1781,\n",
       "   318,\n",
       "   3049,\n",
       "   44756,\n",
       "   290,\n",
       "   340,\n",
       "   338,\n",
       "   845,\n",
       "   4577,\n",
       "   329,\n",
       "   345,\n",
       "   611,\n",
       "   345,\n",
       "   423,\n",
       "   588,\n",
       "   262,\n",
       "   17218,\n",
       "   319,\n",
       "   662,\n",
       "   12,\n",
       "   1818,\n",
       "   13,\n",
       "   1550,\n",
       "   262,\n",
       "   584,\n",
       "   1735,\n",
       "   11,\n",
       "   534,\n",
       "   7743,\n",
       "   1074,\n",
       "   481,\n",
       "   804,\n",
       "   832,\n",
       "   262,\n",
       "   662,\n",
       "   12,\n",
       "   1818,\n",
       "   290,\n",
       "   788,\n",
       "   761,\n",
       "   284,\n",
       "   2148,\n",
       "   617,\n",
       "   7538,\n",
       "   13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.1465743204181114,\n",
       "  'compression_ratio': 1.662037037037037,\n",
       "  'no_speech_prob': 0.0008430780726484954},\n",
       " {'id': 32,\n",
       "  'seek': 2100,\n",
       "  'start': 93.0,\n",
       "  'end': 102.0,\n",
       "  'text': \" And they will start this week and in order to give them a big time to work to go through the pre-work, it's a mandatory to a fit finished by now.\",\n",
       "  'tokens': [843,\n",
       "   484,\n",
       "   481,\n",
       "   923,\n",
       "   428,\n",
       "   1285,\n",
       "   290,\n",
       "   287,\n",
       "   1502,\n",
       "   284,\n",
       "   1577,\n",
       "   606,\n",
       "   257,\n",
       "   1263,\n",
       "   640,\n",
       "   284,\n",
       "   670,\n",
       "   284,\n",
       "   467,\n",
       "   832,\n",
       "   262,\n",
       "   662,\n",
       "   12,\n",
       "   1818,\n",
       "   11,\n",
       "   340,\n",
       "   338,\n",
       "   257,\n",
       "   13677,\n",
       "   284,\n",
       "   257,\n",
       "   4197,\n",
       "   5201,\n",
       "   416,\n",
       "   783,\n",
       "   13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.1465743204181114,\n",
       "  'compression_ratio': 1.662037037037037,\n",
       "  'no_speech_prob': 0.0008430780726484954},\n",
       " {'id': 33,\n",
       "  'seek': 4200,\n",
       "  'start': 102.0,\n",
       "  'end': 90,\n",
       "  'text': ' And also my advice is if you have the time now, also do say zero off career hack because the more you do now, you will be happy during the boot.',\n",
       "  'tokens': [50363,\n",
       "   843,\n",
       "   635,\n",
       "   616,\n",
       "   5608,\n",
       "   318,\n",
       "   611,\n",
       "   345,\n",
       "   423,\n",
       "   262,\n",
       "   640,\n",
       "   783,\n",
       "   11,\n",
       "   635,\n",
       "   466,\n",
       "   910,\n",
       "   6632,\n",
       "   572,\n",
       "   3451,\n",
       "   8156,\n",
       "   780,\n",
       "   262,\n",
       "   517,\n",
       "   345,\n",
       "   466,\n",
       "   783,\n",
       "   11,\n",
       "   345,\n",
       "   481,\n",
       "   307,\n",
       "   3772,\n",
       "   1141,\n",
       "   262,\n",
       "   6297,\n",
       "   13,\n",
       "   50813],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.21920771212191195,\n",
       "  'compression_ratio': 1.2972972972972974,\n",
       "  'no_speech_prob': 1.1644799997156952e-05},\n",
       " {'id': 34,\n",
       "  'seek': 0,\n",
       "  'start': 90.0,\n",
       "  'end': 92.68,\n",
       "  'text': ' And if you already finished with Pework,',\n",
       "  'tokens': [843, 611, 345, 1541, 5201, 351, 350, 6433, 11],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3183304382874085,\n",
       "  'compression_ratio': 1.6284584980237153,\n",
       "  'no_speech_prob': 0.06188422441482544},\n",
       " {'id': 35,\n",
       "  'seek': 0,\n",
       "  'start': 92.68,\n",
       "  'end': 95.28,\n",
       "  'text': ' enjoy the last three Saturday at least.',\n",
       "  'tokens': [2883, 262, 938, 1115, 3909, 379, 1551, 13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3183304382874085,\n",
       "  'compression_ratio': 1.6284584980237153,\n",
       "  'no_speech_prob': 0.06188422441482544},\n",
       " {'id': 36,\n",
       "  'seek': 0,\n",
       "  'start': 95.28,\n",
       "  'end': 98.64,\n",
       "  'text': ' Then what should I expect in the following days?',\n",
       "  'tokens': [3244, 644, 815, 314, 1607, 287, 262, 1708, 1528, 30],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3183304382874085,\n",
       "  'compression_ratio': 1.6284584980237153,\n",
       "  'no_speech_prob': 0.06188422441482544},\n",
       " {'id': 37,\n",
       "  'seek': 0,\n",
       "  'start': 98.64,\n",
       "  'end': 100.36,\n",
       "  'text': ' So today is week zero.',\n",
       "  'tokens': [1406, 1909, 318, 1285, 6632, 13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3183304382874085,\n",
       "  'compression_ratio': 1.6284584980237153,\n",
       "  'no_speech_prob': 0.06188422441482544},\n",
       " {'id': 38,\n",
       "  'seek': 0,\n",
       "  'start': 100.36,\n",
       "  'end': 103.96000000000001,\n",
       "  'text': \" We call it week zero because it's the week before your bootcamp starts.\",\n",
       "  'tokens': [775,\n",
       "   869,\n",
       "   340,\n",
       "   1285,\n",
       "   6632,\n",
       "   780,\n",
       "   340,\n",
       "   338,\n",
       "   262,\n",
       "   1285,\n",
       "   878,\n",
       "   534,\n",
       "   6297,\n",
       "   16544,\n",
       "   4940,\n",
       "   13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3183304382874085,\n",
       "  'compression_ratio': 1.6284584980237153,\n",
       "  'no_speech_prob': 0.06188422441482544},\n",
       " {'id': 39,\n",
       "  'seek': 0,\n",
       "  'start': 103.96000000000001,\n",
       "  'end': 106.03999999999999,\n",
       "  'text': ' And today is day zero.',\n",
       "  'tokens': [843, 1909, 318, 1110, 6632, 13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3183304382874085,\n",
       "  'compression_ratio': 1.6284584980237153,\n",
       "  'no_speech_prob': 0.06188422441482544},\n",
       " {'id': 40,\n",
       "  'seek': 0,\n",
       "  'start': 106.03999999999999,\n",
       "  'end': 110.32,\n",
       "  'text': ' Then in week one, you have your first day of the bootcamp on Tuesday.',\n",
       "  'tokens': [3244,\n",
       "   287,\n",
       "   1285,\n",
       "   530,\n",
       "   11,\n",
       "   345,\n",
       "   423,\n",
       "   534,\n",
       "   717,\n",
       "   1110,\n",
       "   286,\n",
       "   262,\n",
       "   6297,\n",
       "   16544,\n",
       "   319,\n",
       "   3431,\n",
       "   13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3183304382874085,\n",
       "  'compression_ratio': 1.6284584980237153,\n",
       "  'no_speech_prob': 0.06188422441482544},\n",
       " {'id': 41,\n",
       "  'seek': 0,\n",
       "  'start': 110.32,\n",
       "  'end': 113.88,\n",
       "  'text': ' I will send the invitation with the link and all the information.',\n",
       "  'tokens': [314,\n",
       "   481,\n",
       "   3758,\n",
       "   262,\n",
       "   17023,\n",
       "   351,\n",
       "   262,\n",
       "   2792,\n",
       "   290,\n",
       "   477,\n",
       "   262,\n",
       "   1321,\n",
       "   13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3183304382874085,\n",
       "  'compression_ratio': 1.6284584980237153,\n",
       "  'no_speech_prob': 0.06188422441482544},\n",
       " {'id': 42,\n",
       "  'seek': 0,\n",
       "  'start': 113.88,\n",
       "  'end': 116.2,\n",
       "  'text': ' Or after this meeting today,',\n",
       "  'tokens': [1471, 706, 428, 3249, 1909, 11],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3183304382874085,\n",
       "  'compression_ratio': 1.6284584980237153,\n",
       "  'no_speech_prob': 0.06188422441482544},\n",
       " {'id': 43,\n",
       "  'seek': 2620,\n",
       "  'start': 116.2,\n",
       "  'end': 120,\n",
       "  'text': ' so we will start on Tuesday at 6 30 Cent from European time.',\n",
       "  'tokens': [50363,\n",
       "   523,\n",
       "   356,\n",
       "   481,\n",
       "   923,\n",
       "   319,\n",
       "   3431,\n",
       "   379,\n",
       "   718,\n",
       "   1542,\n",
       "   1979,\n",
       "   422,\n",
       "   3427,\n",
       "   640,\n",
       "   13,\n",
       "   50563],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.428070348851821,\n",
       "  'compression_ratio': 0.8823529411764706,\n",
       "  'no_speech_prob': 3.486876920533177e-08},\n",
       " {'id': 44,\n",
       "  'seek': 0,\n",
       "  'start': 120.0,\n",
       "  'end': 123.6,\n",
       "  'text': ' And please be punctual because we will start with a presentation.',\n",
       "  'tokens': [843,\n",
       "   3387,\n",
       "   307,\n",
       "   21025,\n",
       "   723,\n",
       "   780,\n",
       "   356,\n",
       "   481,\n",
       "   923,\n",
       "   351,\n",
       "   257,\n",
       "   10470,\n",
       "   13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2698565141870341,\n",
       "  'compression_ratio': 1.7440944881889764,\n",
       "  'no_speech_prob': 0.075784832239151},\n",
       " {'id': 45,\n",
       "  'seek': 0,\n",
       "  'start': 124.0,\n",
       "  'end': 127.28,\n",
       "  'text': ' And afterwards you start the journey.',\n",
       "  'tokens': [843, 12979, 345, 923, 262, 7002, 13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2698565141870341,\n",
       "  'compression_ratio': 1.7440944881889764,\n",
       "  'no_speech_prob': 0.075784832239151},\n",
       " {'id': 46,\n",
       "  'seek': 0,\n",
       "  'start': 127.28,\n",
       "  'end': 132.16,\n",
       "  'text': ' Then what should I do to successfully complete the doing the bootcamp in terms of',\n",
       "  'tokens': [3244,\n",
       "   644,\n",
       "   815,\n",
       "   314,\n",
       "   466,\n",
       "   284,\n",
       "   7675,\n",
       "   1844,\n",
       "   262,\n",
       "   1804,\n",
       "   262,\n",
       "   6297,\n",
       "   16544,\n",
       "   287,\n",
       "   2846,\n",
       "   286],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2698565141870341,\n",
       "  'compression_ratio': 1.7440944881889764,\n",
       "  'no_speech_prob': 0.075784832239151},\n",
       " {'id': 47,\n",
       "  'seek': 0,\n",
       "  'start': 132.16,\n",
       "  'end': 136.8,\n",
       "  'text': ' dedication? You will need to know that there will be times where you need to work',\n",
       "  'tokens': [22445,\n",
       "   30,\n",
       "   921,\n",
       "   481,\n",
       "   761,\n",
       "   284,\n",
       "   760,\n",
       "   326,\n",
       "   612,\n",
       "   481,\n",
       "   307,\n",
       "   1661,\n",
       "   810,\n",
       "   345,\n",
       "   761,\n",
       "   284,\n",
       "   670],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2698565141870341,\n",
       "  'compression_ratio': 1.7440944881889764,\n",
       "  'no_speech_prob': 0.075784832239151},\n",
       " {'id': 48,\n",
       "  'seek': 0,\n",
       "  'start': 136.8,\n",
       "  'end': 142.32,\n",
       "  'text': ' outside bootcamp hours. So you have to bootcamp hours, but in terms of labs or projects,',\n",
       "  'tokens': [2354,\n",
       "   6297,\n",
       "   16544,\n",
       "   2250,\n",
       "   13,\n",
       "   1406,\n",
       "   345,\n",
       "   423,\n",
       "   284,\n",
       "   6297,\n",
       "   16544,\n",
       "   2250,\n",
       "   11,\n",
       "   475,\n",
       "   287,\n",
       "   2846,\n",
       "   286,\n",
       "   27887,\n",
       "   393,\n",
       "   4493,\n",
       "   11],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2698565141870341,\n",
       "  'compression_ratio': 1.7440944881889764,\n",
       "  'no_speech_prob': 0.075784832239151},\n",
       " {'id': 49,\n",
       "  'seek': 0,\n",
       "  'start': 142.32,\n",
       "  'end': 147.36,\n",
       "  'text': \" for example, you will be asked to work also on other days that I'm not bootcamp hours.\",\n",
       "  'tokens': [329,\n",
       "   1672,\n",
       "   11,\n",
       "   345,\n",
       "   481,\n",
       "   307,\n",
       "   1965,\n",
       "   284,\n",
       "   670,\n",
       "   635,\n",
       "   319,\n",
       "   584,\n",
       "   1528,\n",
       "   326,\n",
       "   314,\n",
       "   1101,\n",
       "   407,\n",
       "   6297,\n",
       "   16544,\n",
       "   2250,\n",
       "   13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.2698565141870341,\n",
       "  'compression_ratio': 1.7440944881889764,\n",
       "  'no_speech_prob': 0.075784832239151},\n",
       " {'id': 50,\n",
       "  'seek': 2736,\n",
       "  'start': 147.36,\n",
       "  'end': 150,\n",
       "  'text': ' And also you will work in individual projects, but also include both checks and activities.',\n",
       "  'tokens': [50363,\n",
       "   843,\n",
       "   635,\n",
       "   345,\n",
       "   481,\n",
       "   670,\n",
       "   287,\n",
       "   1981,\n",
       "   4493,\n",
       "   11,\n",
       "   475,\n",
       "   635,\n",
       "   2291,\n",
       "   1111,\n",
       "   8794,\n",
       "   290,\n",
       "   4568,\n",
       "   13,\n",
       "   50603],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3936087369918823,\n",
       "  'compression_ratio': 1.0963855421686748,\n",
       "  'no_speech_prob': 3.107483621533902e-07},\n",
       " {'id': 51,\n",
       "  'seek': 0,\n",
       "  'start': 150.0,\n",
       "  'end': 155.28,\n",
       "  'text': \" for the in-class dynamics. Please, please have your camera on. You will recognize that it's\",\n",
       "  'tokens': [329,\n",
       "   262,\n",
       "   287,\n",
       "   12,\n",
       "   4871,\n",
       "   17262,\n",
       "   13,\n",
       "   4222,\n",
       "   11,\n",
       "   3387,\n",
       "   423,\n",
       "   534,\n",
       "   4676,\n",
       "   319,\n",
       "   13,\n",
       "   921,\n",
       "   481,\n",
       "   7564,\n",
       "   326,\n",
       "   340,\n",
       "   338],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.17879133565085276,\n",
       "  'compression_ratio': 1.7446043165467626,\n",
       "  'no_speech_prob': 0.041877828538417816},\n",
       " {'id': 52,\n",
       "  'seek': 0,\n",
       "  'start': 155.28,\n",
       "  'end': 161.36,\n",
       "  'text': \" way easier and the way more familiar atmosphere if you can see each other's faces and also connecting\",\n",
       "  'tokens': [835,\n",
       "   4577,\n",
       "   290,\n",
       "   262,\n",
       "   835,\n",
       "   517,\n",
       "   5385,\n",
       "   8137,\n",
       "   611,\n",
       "   345,\n",
       "   460,\n",
       "   766,\n",
       "   1123,\n",
       "   584,\n",
       "   338,\n",
       "   6698,\n",
       "   290,\n",
       "   635,\n",
       "   14320],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.17879133565085276,\n",
       "  'compression_ratio': 1.7446043165467626,\n",
       "  'no_speech_prob': 0.041877828538417816},\n",
       " {'id': 53,\n",
       "  'seek': 0,\n",
       "  'start': 161.36,\n",
       "  'end': 166.96,\n",
       "  'text': \" to each other's way easier and also it provides the teaching team with feedback in how you're\",\n",
       "  'tokens': [284,\n",
       "   1123,\n",
       "   584,\n",
       "   338,\n",
       "   835,\n",
       "   4577,\n",
       "   290,\n",
       "   635,\n",
       "   340,\n",
       "   3769,\n",
       "   262,\n",
       "   7743,\n",
       "   1074,\n",
       "   351,\n",
       "   7538,\n",
       "   287,\n",
       "   703,\n",
       "   345,\n",
       "   821],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.17879133565085276,\n",
       "  'compression_ratio': 1.7446043165467626,\n",
       "  'no_speech_prob': 0.041877828538417816},\n",
       " {'id': 54,\n",
       "  'seek': 0,\n",
       "  'start': 166.96,\n",
       "  'end': 171.2,\n",
       "  'text': \" getting the content or if you're completely locked. The mics are turned off during the lecture time,\",\n",
       "  'tokens': [1972,\n",
       "   262,\n",
       "   2695,\n",
       "   393,\n",
       "   611,\n",
       "   345,\n",
       "   821,\n",
       "   3190,\n",
       "   8970,\n",
       "   13,\n",
       "   383,\n",
       "   285,\n",
       "   873,\n",
       "   389,\n",
       "   2900,\n",
       "   572,\n",
       "   1141,\n",
       "   262,\n",
       "   19143,\n",
       "   640,\n",
       "   11],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.17879133565085276,\n",
       "  'compression_ratio': 1.7446043165467626,\n",
       "  'no_speech_prob': 0.041877828538417816},\n",
       " {'id': 55,\n",
       "  'seek': 0,\n",
       "  'start': 171.2,\n",
       "  'end': 176.48,\n",
       "  'text': ' but of course if you have any questions just turn off your turn on your mic and ask the question',\n",
       "  'tokens': [475,\n",
       "   286,\n",
       "   1781,\n",
       "   611,\n",
       "   345,\n",
       "   423,\n",
       "   597,\n",
       "   2683,\n",
       "   655,\n",
       "   1210,\n",
       "   572,\n",
       "   534,\n",
       "   1210,\n",
       "   319,\n",
       "   534,\n",
       "   12314,\n",
       "   290,\n",
       "   1265,\n",
       "   262,\n",
       "   1808],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.17879133565085276,\n",
       "  'compression_ratio': 1.7446043165467626,\n",
       "  'no_speech_prob': 0.041877828538417816},\n",
       " {'id': 56,\n",
       "  'seek': 2648,\n",
       "  'start': 176.48,\n",
       "  'end': 182.32,\n",
       "  'text': \" and don't be shy after any questions because even if you are the only one asking, I'm 100% sure,\",\n",
       "  'tokens': [290,\n",
       "   836,\n",
       "   470,\n",
       "   307,\n",
       "   15800,\n",
       "   706,\n",
       "   597,\n",
       "   2683,\n",
       "   780,\n",
       "   772,\n",
       "   611,\n",
       "   345,\n",
       "   389,\n",
       "   262,\n",
       "   691,\n",
       "   530,\n",
       "   4737,\n",
       "   11,\n",
       "   314,\n",
       "   1101,\n",
       "   1802,\n",
       "   4,\n",
       "   1654,\n",
       "   11],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.369938147695441,\n",
       "  'compression_ratio': 1.2264150943396226,\n",
       "  'no_speech_prob': 4.601291436756583e-08},\n",
       " {'id': 57,\n",
       "  'seek': 3232,\n",
       "  'start': 182.32,\n",
       "  'end': 180,\n",
       "  'text': \" you're not the only one with the\",\n",
       "  'tokens': [50363, 345, 821, 407, 262, 691, 530, 351, 262, 51567],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.7507237521084872,\n",
       "  'compression_ratio': 0.8888888888888888,\n",
       "  'no_speech_prob': 4.2281162677682005e-06},\n",
       " {'id': 58,\n",
       "  'seek': 0,\n",
       "  'start': 180.0,\n",
       "  'end': 188.0,\n",
       "  'text': \" In terms of graduation, so we don't work with grades at Ironheck, but we have other criteria to fulfill in order to graduate.\",\n",
       "  'tokens': [554,\n",
       "   2846,\n",
       "   286,\n",
       "   21571,\n",
       "   11,\n",
       "   523,\n",
       "   356,\n",
       "   836,\n",
       "   470,\n",
       "   670,\n",
       "   351,\n",
       "   19051,\n",
       "   379,\n",
       "   7931,\n",
       "   258,\n",
       "   694,\n",
       "   11,\n",
       "   475,\n",
       "   356,\n",
       "   423,\n",
       "   584,\n",
       "   9987,\n",
       "   284,\n",
       "   14658,\n",
       "   287,\n",
       "   1502,\n",
       "   284,\n",
       "   10428,\n",
       "   13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.21273066872044613,\n",
       "  'compression_ratio': 1.6623376623376624,\n",
       "  'no_speech_prob': 0.0999273881316185},\n",
       " {'id': 59,\n",
       "  'seek': 0,\n",
       "  'start': 188.0,\n",
       "  'end': 194.0,\n",
       "  'text': \" The first one is the attendance. So you're not allowed to miss more than seven classes or you want graduate.\",\n",
       "  'tokens': [383,\n",
       "   717,\n",
       "   530,\n",
       "   318,\n",
       "   262,\n",
       "   14858,\n",
       "   13,\n",
       "   1406,\n",
       "   345,\n",
       "   821,\n",
       "   407,\n",
       "   3142,\n",
       "   284,\n",
       "   2051,\n",
       "   517,\n",
       "   621,\n",
       "   3598,\n",
       "   6097,\n",
       "   393,\n",
       "   345,\n",
       "   765,\n",
       "   10428,\n",
       "   13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.21273066872044613,\n",
       "  'compression_ratio': 1.6623376623376624,\n",
       "  'no_speech_prob': 0.0999273881316185},\n",
       " {'id': 60,\n",
       "  'seek': 0,\n",
       "  'start': 194.0,\n",
       "  'end': 202.0,\n",
       "  'text': ' And in terms of form neutrality, if you arrive ten minutes to late, it counts as a party. And if you have three parties, it counts as an absence day.',\n",
       "  'tokens': [843,\n",
       "   287,\n",
       "   2846,\n",
       "   286,\n",
       "   1296,\n",
       "   20723,\n",
       "   11,\n",
       "   611,\n",
       "   345,\n",
       "   9240,\n",
       "   3478,\n",
       "   2431,\n",
       "   284,\n",
       "   2739,\n",
       "   11,\n",
       "   340,\n",
       "   9853,\n",
       "   355,\n",
       "   257,\n",
       "   2151,\n",
       "   13,\n",
       "   843,\n",
       "   611,\n",
       "   345,\n",
       "   423,\n",
       "   1115,\n",
       "   4671,\n",
       "   11,\n",
       "   340,\n",
       "   9853,\n",
       "   355,\n",
       "   281,\n",
       "   8889,\n",
       "   1110,\n",
       "   13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.21273066872044613,\n",
       "  'compression_ratio': 1.6623376623376624,\n",
       "  'no_speech_prob': 0.0999273881316185},\n",
       " {'id': 61,\n",
       "  'seek': 2200,\n",
       "  'start': 202.0,\n",
       "  'end': 210.0,\n",
       "  'text': \" So meaning if you arrive three times ten minutes late, it counts as if you wouldn't be there for one day. In terms of labs.\",\n",
       "  'tokens': [1406,\n",
       "   3616,\n",
       "   611,\n",
       "   345,\n",
       "   9240,\n",
       "   1115,\n",
       "   1661,\n",
       "   3478,\n",
       "   2431,\n",
       "   2739,\n",
       "   11,\n",
       "   340,\n",
       "   9853,\n",
       "   355,\n",
       "   611,\n",
       "   345,\n",
       "   3636,\n",
       "   470,\n",
       "   307,\n",
       "   612,\n",
       "   329,\n",
       "   530,\n",
       "   1110,\n",
       "   13,\n",
       "   554,\n",
       "   2846,\n",
       "   286,\n",
       "   27887,\n",
       "   13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.1324848425192911,\n",
       "  'compression_ratio': 1.478021978021978,\n",
       "  'no_speech_prob': 8.806073310552165e-05},\n",
       " {'id': 62,\n",
       "  'seek': 3000,\n",
       "  'start': 210.0,\n",
       "  'end': 210,\n",
       "  'text': ' Of course, we recommend to have a hundred percent lab competition because the labs are the perfect time to put everything you learned in practice.',\n",
       "  'tokens': [50363,\n",
       "   3226,\n",
       "   1781,\n",
       "   11,\n",
       "   356,\n",
       "   4313,\n",
       "   284,\n",
       "   423,\n",
       "   257,\n",
       "   3470,\n",
       "   1411,\n",
       "   2248,\n",
       "   5449,\n",
       "   780,\n",
       "   262,\n",
       "   27887,\n",
       "   389,\n",
       "   262,\n",
       "   2818,\n",
       "   640,\n",
       "   284,\n",
       "   1234,\n",
       "   2279,\n",
       "   345,\n",
       "   4499,\n",
       "   287,\n",
       "   3357,\n",
       "   13,\n",
       "   50763],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.1835405985514323,\n",
       "  'compression_ratio': 1.3035714285714286,\n",
       "  'no_speech_prob': 0.0009471137309446931},\n",
       " {'id': 63,\n",
       "  'seek': 0,\n",
       "  'start': 210.0,\n",
       "  'end': 214.64,\n",
       "  'text': ' So you do yourself, it do yourself a favor if you do 100% of the labs.',\n",
       "  'tokens': [1406,\n",
       "   345,\n",
       "   466,\n",
       "   3511,\n",
       "   11,\n",
       "   340,\n",
       "   466,\n",
       "   3511,\n",
       "   257,\n",
       "   2661,\n",
       "   611,\n",
       "   345,\n",
       "   466,\n",
       "   1802,\n",
       "   4,\n",
       "   286,\n",
       "   262,\n",
       "   27887,\n",
       "   13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3040227274740896,\n",
       "  'compression_ratio': 1.7279693486590038,\n",
       "  'no_speech_prob': 0.04369121417403221},\n",
       " {'id': 64,\n",
       "  'seek': 0,\n",
       "  'start': 214.64,\n",
       "  'end': 217.8,\n",
       "  'text': \" But if you do less than 80%, you won't graduate.\",\n",
       "  'tokens': [887,\n",
       "   611,\n",
       "   345,\n",
       "   466,\n",
       "   1342,\n",
       "   621,\n",
       "   4019,\n",
       "   7441,\n",
       "   345,\n",
       "   1839,\n",
       "   470,\n",
       "   10428,\n",
       "   13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3040227274740896,\n",
       "  'compression_ratio': 1.7279693486590038,\n",
       "  'no_speech_prob': 0.04369121417403221},\n",
       " {'id': 65,\n",
       "  'seek': 0,\n",
       "  'start': 217.8,\n",
       "  'end': 222.6,\n",
       "  'text': ' And in terms of the project, which is the third criteria to graduate,',\n",
       "  'tokens': [843,\n",
       "   287,\n",
       "   2846,\n",
       "   286,\n",
       "   262,\n",
       "   1628,\n",
       "   11,\n",
       "   543,\n",
       "   318,\n",
       "   262,\n",
       "   2368,\n",
       "   9987,\n",
       "   284,\n",
       "   10428,\n",
       "   11],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3040227274740896,\n",
       "  'compression_ratio': 1.7279693486590038,\n",
       "  'no_speech_prob': 0.04369121417403221},\n",
       " {'id': 66,\n",
       "  'seek': 0,\n",
       "  'start': 222.6,\n",
       "  'end': 225.88,\n",
       "  'text': ' you will need to present them and do all of them by your own,',\n",
       "  'tokens': [345,\n",
       "   481,\n",
       "   761,\n",
       "   284,\n",
       "   1944,\n",
       "   606,\n",
       "   290,\n",
       "   466,\n",
       "   477,\n",
       "   286,\n",
       "   606,\n",
       "   416,\n",
       "   534,\n",
       "   898,\n",
       "   11],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3040227274740896,\n",
       "  'compression_ratio': 1.7279693486590038,\n",
       "  'no_speech_prob': 0.04369121417403221},\n",
       " {'id': 67,\n",
       "  'seek': 0,\n",
       "  'start': 225.88,\n",
       "  'end': 228.76,\n",
       "  'text': ' and they need to be up to a certain standard.',\n",
       "  'tokens': [290, 484, 761, 284, 307, 510, 284, 257, 1728, 3210, 13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3040227274740896,\n",
       "  'compression_ratio': 1.7279693486590038,\n",
       "  'no_speech_prob': 0.04369121417403221},\n",
       " {'id': 68,\n",
       "  'seek': 0,\n",
       "  'start': 228.76,\n",
       "  'end': 231.4,\n",
       "  'text': ' Then who will be my point of contact?',\n",
       "  'tokens': [3244, 508, 481, 307, 616, 966, 286, 2800, 30],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3040227274740896,\n",
       "  'compression_ratio': 1.7279693486590038,\n",
       "  'no_speech_prob': 0.04369121417403221},\n",
       " {'id': 69,\n",
       "  'seek': 0,\n",
       "  'start': 231.4,\n",
       "  'end': 235.28,\n",
       "  'text': ' There are several people involved in your iron-head experience,',\n",
       "  'tokens': [1318, 389, 1811, 661, 2950, 287, 534, 6953, 12, 2256, 1998, 11],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3040227274740896,\n",
       "  'compression_ratio': 1.7279693486590038,\n",
       "  'no_speech_prob': 0.04369121417403221},\n",
       " {'id': 70,\n",
       "  'seek': 0,\n",
       "  'start': 235.28,\n",
       "  'end': 238.64,\n",
       "  'text': ' which is firstly your lead teacher, which is David.',\n",
       "  'tokens': [543, 318, 717, 306, 534, 1085, 4701, 11, 543, 318, 3271, 13],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.3040227274740896,\n",
       "  'compression_ratio': 1.7279693486590038,\n",
       "  'no_speech_prob': 0.04369121417403221},\n",
       " {'id': 71,\n",
       "  'seek': 2864,\n",
       "  'start': 238.64,\n",
       "  'end': 240.28,\n",
       "  'text': \" Please don't recall.\",\n",
       "  'tokens': [50363, 4222, 836, 470, 10014, 13, 50445],\n",
       "  'temperature': 1.0,\n",
       "  'avg_logprob': -2.2677810192108154,\n",
       "  'compression_ratio': 0.7142857142857143,\n",
       "  'no_speech_prob': 7.88377860772016e-07}]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repairTranscriptSegments(segments_final,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f47ad38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c2f1846f3955305d6cdcd7be5897be31bd89b0ce061940c94fabaf8ec721e2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
